{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJaw6sbHHJdo"
      },
      "source": [
        "# Necessary Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ba_slnjGDp0R"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5h2AVf4xHOAs"
      },
      "source": [
        "# Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "YoSA7AbwHHW4",
        "outputId": "2ace4455-a640-4eb9-e776-a1ba31eed1aa"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>age</th>\n",
              "      <th>bp</th>\n",
              "      <th>sg</th>\n",
              "      <th>al</th>\n",
              "      <th>su</th>\n",
              "      <th>rbc</th>\n",
              "      <th>pc</th>\n",
              "      <th>pcc</th>\n",
              "      <th>ba</th>\n",
              "      <th>...</th>\n",
              "      <th>pcv</th>\n",
              "      <th>wc</th>\n",
              "      <th>rc</th>\n",
              "      <th>htn</th>\n",
              "      <th>dm</th>\n",
              "      <th>cad</th>\n",
              "      <th>appet</th>\n",
              "      <th>pe</th>\n",
              "      <th>ane</th>\n",
              "      <th>classification</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>1.020</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>normal</td>\n",
              "      <td>notpresent</td>\n",
              "      <td>notpresent</td>\n",
              "      <td>...</td>\n",
              "      <td>44</td>\n",
              "      <td>7800</td>\n",
              "      <td>5.2</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>good</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>ckd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>7.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1.020</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>normal</td>\n",
              "      <td>notpresent</td>\n",
              "      <td>notpresent</td>\n",
              "      <td>...</td>\n",
              "      <td>38</td>\n",
              "      <td>6000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>good</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>ckd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>62.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>1.010</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>normal</td>\n",
              "      <td>normal</td>\n",
              "      <td>notpresent</td>\n",
              "      <td>notpresent</td>\n",
              "      <td>...</td>\n",
              "      <td>31</td>\n",
              "      <td>7500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>poor</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>ckd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>48.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>1.005</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>normal</td>\n",
              "      <td>abnormal</td>\n",
              "      <td>present</td>\n",
              "      <td>notpresent</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>6700</td>\n",
              "      <td>3.9</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>poor</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>ckd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>51.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>1.010</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>normal</td>\n",
              "      <td>normal</td>\n",
              "      <td>notpresent</td>\n",
              "      <td>notpresent</td>\n",
              "      <td>...</td>\n",
              "      <td>35</td>\n",
              "      <td>7300</td>\n",
              "      <td>4.6</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>good</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>ckd</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 26 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   id   age    bp     sg   al   su     rbc        pc         pcc          ba  \\\n",
              "0   0  48.0  80.0  1.020  1.0  0.0     NaN    normal  notpresent  notpresent   \n",
              "1   1   7.0  50.0  1.020  4.0  0.0     NaN    normal  notpresent  notpresent   \n",
              "2   2  62.0  80.0  1.010  2.0  3.0  normal    normal  notpresent  notpresent   \n",
              "3   3  48.0  70.0  1.005  4.0  0.0  normal  abnormal     present  notpresent   \n",
              "4   4  51.0  80.0  1.010  2.0  0.0  normal    normal  notpresent  notpresent   \n",
              "\n",
              "   ...  pcv    wc   rc  htn   dm  cad appet   pe  ane classification  \n",
              "0  ...   44  7800  5.2  yes  yes   no  good   no   no            ckd  \n",
              "1  ...   38  6000  NaN   no   no   no  good   no   no            ckd  \n",
              "2  ...   31  7500  NaN   no  yes   no  poor   no  yes            ckd  \n",
              "3  ...   32  6700  3.9  yes   no   no  poor  yes  yes            ckd  \n",
              "4  ...   35  7300  4.6   no   no   no  good   no   no            ckd  \n",
              "\n",
              "[5 rows x 26 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('kidney_disease.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTU_W677T6MH",
        "outputId": "cca7faf3-0e2a-4c88-ad91-7fdb0074e1b6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "51.48337595907928"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['age'].mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UfeQyhQHlT_",
        "outputId": "96b7302f-4caa-436b-8417-6c615f4cd7f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(400, 26)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDXN_uuoHtng"
      },
      "source": [
        "# Dropping id Column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZdQUTwh9HrDw"
      },
      "outputs": [],
      "source": [
        "df.drop('id',axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "-qzTbjrpH7SH",
        "outputId": "787d51c0-e856-4b45-e9a1-02a96bb09e83"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bp</th>\n",
              "      <th>sg</th>\n",
              "      <th>al</th>\n",
              "      <th>su</th>\n",
              "      <th>rbc</th>\n",
              "      <th>pc</th>\n",
              "      <th>pcc</th>\n",
              "      <th>ba</th>\n",
              "      <th>bgr</th>\n",
              "      <th>...</th>\n",
              "      <th>pcv</th>\n",
              "      <th>wc</th>\n",
              "      <th>rc</th>\n",
              "      <th>htn</th>\n",
              "      <th>dm</th>\n",
              "      <th>cad</th>\n",
              "      <th>appet</th>\n",
              "      <th>pe</th>\n",
              "      <th>ane</th>\n",
              "      <th>classification</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>48.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>1.020</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>normal</td>\n",
              "      <td>notpresent</td>\n",
              "      <td>notpresent</td>\n",
              "      <td>121.0</td>\n",
              "      <td>...</td>\n",
              "      <td>44</td>\n",
              "      <td>7800</td>\n",
              "      <td>5.2</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>good</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>ckd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1.020</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>normal</td>\n",
              "      <td>notpresent</td>\n",
              "      <td>notpresent</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>38</td>\n",
              "      <td>6000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>good</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>ckd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>62.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>1.010</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>normal</td>\n",
              "      <td>normal</td>\n",
              "      <td>notpresent</td>\n",
              "      <td>notpresent</td>\n",
              "      <td>423.0</td>\n",
              "      <td>...</td>\n",
              "      <td>31</td>\n",
              "      <td>7500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>poor</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>ckd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>48.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>1.005</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>normal</td>\n",
              "      <td>abnormal</td>\n",
              "      <td>present</td>\n",
              "      <td>notpresent</td>\n",
              "      <td>117.0</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>6700</td>\n",
              "      <td>3.9</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>poor</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>ckd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>51.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>1.010</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>normal</td>\n",
              "      <td>normal</td>\n",
              "      <td>notpresent</td>\n",
              "      <td>notpresent</td>\n",
              "      <td>106.0</td>\n",
              "      <td>...</td>\n",
              "      <td>35</td>\n",
              "      <td>7300</td>\n",
              "      <td>4.6</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>good</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>ckd</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 25 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    age    bp     sg   al   su     rbc        pc         pcc          ba  \\\n",
              "0  48.0  80.0  1.020  1.0  0.0     NaN    normal  notpresent  notpresent   \n",
              "1   7.0  50.0  1.020  4.0  0.0     NaN    normal  notpresent  notpresent   \n",
              "2  62.0  80.0  1.010  2.0  3.0  normal    normal  notpresent  notpresent   \n",
              "3  48.0  70.0  1.005  4.0  0.0  normal  abnormal     present  notpresent   \n",
              "4  51.0  80.0  1.010  2.0  0.0  normal    normal  notpresent  notpresent   \n",
              "\n",
              "     bgr  ...  pcv    wc   rc  htn   dm cad appet   pe  ane classification  \n",
              "0  121.0  ...   44  7800  5.2  yes  yes  no  good   no   no            ckd  \n",
              "1    NaN  ...   38  6000  NaN   no   no  no  good   no   no            ckd  \n",
              "2  423.0  ...   31  7500  NaN   no  yes  no  poor   no  yes            ckd  \n",
              "3  117.0  ...   32  6700  3.9  yes   no  no  poor  yes  yes            ckd  \n",
              "4  106.0  ...   35  7300  4.6   no   no  no  good   no   no            ckd  \n",
              "\n",
              "[5 rows x 25 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "6UAQ3RqPIMAk",
        "outputId": "94c1c18b-3415-46bc-aadd-ddf091758026"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bp</th>\n",
              "      <th>sg</th>\n",
              "      <th>al</th>\n",
              "      <th>su</th>\n",
              "      <th>bgr</th>\n",
              "      <th>bu</th>\n",
              "      <th>sc</th>\n",
              "      <th>sod</th>\n",
              "      <th>pot</th>\n",
              "      <th>hemo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>391.000000</td>\n",
              "      <td>388.000000</td>\n",
              "      <td>353.000000</td>\n",
              "      <td>354.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>356.000000</td>\n",
              "      <td>381.000000</td>\n",
              "      <td>383.000000</td>\n",
              "      <td>313.000000</td>\n",
              "      <td>312.000000</td>\n",
              "      <td>348.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>51.483376</td>\n",
              "      <td>76.469072</td>\n",
              "      <td>1.017408</td>\n",
              "      <td>1.016949</td>\n",
              "      <td>0.450142</td>\n",
              "      <td>148.036517</td>\n",
              "      <td>57.425722</td>\n",
              "      <td>3.072454</td>\n",
              "      <td>137.528754</td>\n",
              "      <td>4.627244</td>\n",
              "      <td>12.526437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>17.169714</td>\n",
              "      <td>13.683637</td>\n",
              "      <td>0.005717</td>\n",
              "      <td>1.352679</td>\n",
              "      <td>1.099191</td>\n",
              "      <td>79.281714</td>\n",
              "      <td>50.503006</td>\n",
              "      <td>5.741126</td>\n",
              "      <td>10.408752</td>\n",
              "      <td>3.193904</td>\n",
              "      <td>2.912587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>1.005000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>4.500000</td>\n",
              "      <td>2.500000</td>\n",
              "      <td>3.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>42.000000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>1.010000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>135.000000</td>\n",
              "      <td>3.800000</td>\n",
              "      <td>10.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>55.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>1.020000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>121.000000</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>1.300000</td>\n",
              "      <td>138.000000</td>\n",
              "      <td>4.400000</td>\n",
              "      <td>12.650000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>64.500000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>1.020000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>163.000000</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>2.800000</td>\n",
              "      <td>142.000000</td>\n",
              "      <td>4.900000</td>\n",
              "      <td>15.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>90.000000</td>\n",
              "      <td>180.000000</td>\n",
              "      <td>1.025000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>490.000000</td>\n",
              "      <td>391.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>163.000000</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>17.800000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              age          bp          sg          al          su         bgr  \\\n",
              "count  391.000000  388.000000  353.000000  354.000000  351.000000  356.000000   \n",
              "mean    51.483376   76.469072    1.017408    1.016949    0.450142  148.036517   \n",
              "std     17.169714   13.683637    0.005717    1.352679    1.099191   79.281714   \n",
              "min      2.000000   50.000000    1.005000    0.000000    0.000000   22.000000   \n",
              "25%     42.000000   70.000000    1.010000    0.000000    0.000000   99.000000   \n",
              "50%     55.000000   80.000000    1.020000    0.000000    0.000000  121.000000   \n",
              "75%     64.500000   80.000000    1.020000    2.000000    0.000000  163.000000   \n",
              "max     90.000000  180.000000    1.025000    5.000000    5.000000  490.000000   \n",
              "\n",
              "               bu          sc         sod         pot        hemo  \n",
              "count  381.000000  383.000000  313.000000  312.000000  348.000000  \n",
              "mean    57.425722    3.072454  137.528754    4.627244   12.526437  \n",
              "std     50.503006    5.741126   10.408752    3.193904    2.912587  \n",
              "min      1.500000    0.400000    4.500000    2.500000    3.100000  \n",
              "25%     27.000000    0.900000  135.000000    3.800000   10.300000  \n",
              "50%     42.000000    1.300000  138.000000    4.400000   12.650000  \n",
              "75%     66.000000    2.800000  142.000000    4.900000   15.000000  \n",
              "max    391.000000   76.000000  163.000000   47.000000   17.800000  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wp3kiElHI7Gs",
        "outputId": "aca8d49b-4bb0-4355-c5ab-71b822b05112"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 400 entries, 0 to 399\n",
            "Data columns (total 25 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   age             391 non-null    float64\n",
            " 1   bp              388 non-null    float64\n",
            " 2   sg              353 non-null    float64\n",
            " 3   al              354 non-null    float64\n",
            " 4   su              351 non-null    float64\n",
            " 5   rbc             248 non-null    object \n",
            " 6   pc              335 non-null    object \n",
            " 7   pcc             396 non-null    object \n",
            " 8   ba              396 non-null    object \n",
            " 9   bgr             356 non-null    float64\n",
            " 10  bu              381 non-null    float64\n",
            " 11  sc              383 non-null    float64\n",
            " 12  sod             313 non-null    float64\n",
            " 13  pot             312 non-null    float64\n",
            " 14  hemo            348 non-null    float64\n",
            " 15  pcv             330 non-null    object \n",
            " 16  wc              295 non-null    object \n",
            " 17  rc              270 non-null    object \n",
            " 18  htn             398 non-null    object \n",
            " 19  dm              398 non-null    object \n",
            " 20  cad             398 non-null    object \n",
            " 21  appet           399 non-null    object \n",
            " 22  pe              399 non-null    object \n",
            " 23  ane             399 non-null    object \n",
            " 24  classification  400 non-null    object \n",
            "dtypes: float64(11), object(14)\n",
            "memory usage: 78.3+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1B7dFf0FKF-j"
      },
      "source": [
        "# Convert into Numeric Dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "NFvdMWAcKFWS"
      },
      "outputs": [],
      "source": [
        "df['pcv'] = pd.to_numeric(df['pcv'],errors = 'coerce')\n",
        "df['wc'] = pd.to_numeric(df['wc'],errors = 'coerce')\n",
        "df['rc'] = pd.to_numeric(df['rc'],errors = 'coerce')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6xN_aHCMP50",
        "outputId": "9da40983-d7d4-4686-8835-797c011b3623"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 400 entries, 0 to 399\n",
            "Data columns (total 25 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   age             391 non-null    float64\n",
            " 1   bp              388 non-null    float64\n",
            " 2   sg              353 non-null    float64\n",
            " 3   al              354 non-null    float64\n",
            " 4   su              351 non-null    float64\n",
            " 5   rbc             248 non-null    object \n",
            " 6   pc              335 non-null    object \n",
            " 7   pcc             396 non-null    object \n",
            " 8   ba              396 non-null    object \n",
            " 9   bgr             356 non-null    float64\n",
            " 10  bu              381 non-null    float64\n",
            " 11  sc              383 non-null    float64\n",
            " 12  sod             313 non-null    float64\n",
            " 13  pot             312 non-null    float64\n",
            " 14  hemo            348 non-null    float64\n",
            " 15  pcv             329 non-null    float64\n",
            " 16  wc              294 non-null    float64\n",
            " 17  rc              269 non-null    float64\n",
            " 18  htn             398 non-null    object \n",
            " 19  dm              398 non-null    object \n",
            " 20  cad             398 non-null    object \n",
            " 21  appet           399 non-null    object \n",
            " 22  pe              399 non-null    object \n",
            " 23  ane             399 non-null    object \n",
            " 24  classification  400 non-null    object \n",
            "dtypes: float64(14), object(11)\n",
            "memory usage: 78.3+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLvUw6kLMuKq"
      },
      "source": [
        "# **Extracting Categorical**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9nEB6MVMtxZ",
        "outputId": "0ce3c8e8-64ab-45e7-f86c-be9482c5cfe2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['rbc',\n",
              " 'pc',\n",
              " 'pcc',\n",
              " 'ba',\n",
              " 'htn',\n",
              " 'dm',\n",
              " 'cad',\n",
              " 'appet',\n",
              " 'pe',\n",
              " 'ane',\n",
              " 'classification']"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cat_cols = [col for col in df.columns if df[col].dtype == 'object']\n",
        "cat_cols"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2KN5en__LJC"
      },
      "source": [
        "# **Extracting Numerical**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nusjunu8NMYw",
        "outputId": "d33ac97f-9cc1-4499-e221-c186235d7a75"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['age',\n",
              " 'bp',\n",
              " 'sg',\n",
              " 'al',\n",
              " 'su',\n",
              " 'bgr',\n",
              " 'bu',\n",
              " 'sc',\n",
              " 'sod',\n",
              " 'pot',\n",
              " 'hemo',\n",
              " 'pcv',\n",
              " 'wc',\n",
              " 'rc']"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "num_cols = [col for col in df.columns if df[col].dtype != 'object']\n",
        "num_cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpSOrYkONV0d",
        "outputId": "da33fbd2-8db1-4990-af21-fed34ba9ec99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 400 entries, 0 to 399\n",
            "Data columns (total 25 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   age             391 non-null    float64\n",
            " 1   bp              388 non-null    float64\n",
            " 2   sg              353 non-null    float64\n",
            " 3   al              354 non-null    float64\n",
            " 4   su              351 non-null    float64\n",
            " 5   rbc             248 non-null    object \n",
            " 6   pc              335 non-null    object \n",
            " 7   pcc             396 non-null    object \n",
            " 8   ba              396 non-null    object \n",
            " 9   bgr             356 non-null    float64\n",
            " 10  bu              381 non-null    float64\n",
            " 11  sc              383 non-null    float64\n",
            " 12  sod             313 non-null    float64\n",
            " 13  pot             312 non-null    float64\n",
            " 14  hemo            348 non-null    float64\n",
            " 15  pcv             329 non-null    float64\n",
            " 16  wc              294 non-null    float64\n",
            " 17  rc              269 non-null    float64\n",
            " 18  htn             398 non-null    object \n",
            " 19  dm              398 non-null    object \n",
            " 20  cad             398 non-null    object \n",
            " 21  appet           399 non-null    object \n",
            " 22  pe              399 non-null    object \n",
            " 23  ane             399 non-null    object \n",
            " 24  classification  400 non-null    object \n",
            "dtypes: float64(14), object(11)\n",
            "memory usage: 78.3+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UN9tTwDSNgjn"
      },
      "source": [
        "# Get unique values from categorical columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWyVQW2SNgCH",
        "outputId": "6684ad49-f1cf-403a-c14a-f5dd1868c98d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rbc ---> [nan 'normal' 'abnormal'] values\n",
            "pc ---> ['normal' 'abnormal' nan] values\n",
            "pcc ---> ['notpresent' 'present' nan] values\n",
            "ba ---> ['notpresent' 'present' nan] values\n",
            "htn ---> ['yes' 'no' nan] values\n",
            "dm ---> ['yes' 'no' ' yes' '\\tno' '\\tyes' nan] values\n",
            "cad ---> ['no' 'yes' '\\tno' nan] values\n",
            "appet ---> ['good' 'poor' nan] values\n",
            "pe ---> ['no' 'yes' nan] values\n",
            "ane ---> ['no' 'yes' nan] values\n",
            "classification ---> ['ckd' 'ckd\\t' 'notckd'] values\n"
          ]
        }
      ],
      "source": [
        "for col in cat_cols:\n",
        "  print(f\"{col} ---> {df[col].unique()} values\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zstg9WoYOEzq"
      },
      "source": [
        "# Remove Ambiguity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "8l8pgmvKOHuk"
      },
      "outputs": [],
      "source": [
        "df['dm'].replace(to_replace={'\\tno' : 'no','\\tyes':'yes','yes':'yes',' yes':'yes'},inplace=True)\n",
        "df['cad'].replace(to_replace={'\\tno' : 'no','\\tyes':'yes','yes':'yes',' yes':'yes'},inplace=True)\n",
        "df['classification'].replace(to_replace={'ckd\\t' : 'ckd','notckd':'notckd'},inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yNugp1ePwLN"
      },
      "source": [
        "# Convert categorical to numeric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "mLGvhVp_Py8w"
      },
      "outputs": [],
      "source": [
        "#df['classification'] = df['classification'].map()\n",
        "df['classification'].replace(to_replace={'ckd':0,'notckd':1},inplace=True)\n",
        "#df['classification'] = pd.to_numeric(df['classification'],errors='coerce')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PN0GQLdPRJwJ",
        "outputId": "8e030a22-1bb5-4b3e-9cee-817224e58aad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0      0\n",
              "1      0\n",
              "2      0\n",
              "3      0\n",
              "4      0\n",
              "      ..\n",
              "395    1\n",
              "396    1\n",
              "397    1\n",
              "398    1\n",
              "399    1\n",
              "Name: classification, Length: 400, dtype: int64"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['classification']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLtUo8N0Q5H8",
        "outputId": "f1f5ccaf-e16e-4108-b7e0-565e27ea527c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rbc ---> [nan 'normal' 'abnormal'] values\n",
            "pc ---> ['normal' 'abnormal' nan] values\n",
            "pcc ---> ['notpresent' 'present' nan] values\n",
            "ba ---> ['notpresent' 'present' nan] values\n",
            "htn ---> ['yes' 'no' nan] values\n",
            "dm ---> ['yes' 'no' nan] values\n",
            "cad ---> ['no' 'yes' nan] values\n",
            "appet ---> ['good' 'poor' nan] values\n",
            "pe ---> ['no' 'yes' nan] values\n",
            "ane ---> ['no' 'yes' nan] values\n",
            "classification ---> [0 1] values\n"
          ]
        }
      ],
      "source": [
        "\n",
        "for col in cat_cols:\n",
        "  print(f\"{col} ---> {df[col].unique()} values\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "lYYEL30xAtib"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "age ---> [48.  7. 62. 51. 60. 68. 24. 52. 53. 50. 63. 40. 47. 61. 21. 42. 75. 69.\n",
            " nan 73. 70. 65. 76. 72. 82. 46. 45. 35. 54. 11. 59. 67. 15. 55. 44. 26.\n",
            " 64. 56.  5. 74. 38. 58. 71. 34. 17. 12. 43. 41. 57.  8. 39. 66. 81. 14.\n",
            " 27. 83. 30.  4.  3.  6. 32. 80. 49. 90. 78. 19.  2. 33. 36. 37. 23. 25.\n",
            " 20. 29. 28. 22. 79.] values\n",
            "bp ---> [ 80.  50.  70.  90.  nan 100.  60. 110. 140. 180. 120.] values\n",
            "sg ---> [1.02  1.01  1.005 1.015   nan 1.025] values\n",
            "al ---> [ 1.  4.  2.  3.  0. nan  5.] values\n",
            "su ---> [ 0.  3.  4.  1. nan  2.  5.] values\n",
            "bgr ---> [121.  nan 423. 117. 106.  74. 100. 410. 138.  70. 490. 380. 208.  98.\n",
            " 157.  76.  99. 114. 263. 173.  95. 108. 156. 264. 123.  93. 107. 159.\n",
            " 140. 171. 270.  92. 137. 204.  79. 207. 124. 144.  91. 162. 246. 253.\n",
            " 141. 182.  86. 150. 146. 425. 112. 250. 360. 163. 129. 133. 102. 158.\n",
            " 165. 132. 104. 127. 415. 169. 251. 109. 280. 210. 219. 295.  94. 172.\n",
            " 101. 298. 153.  88. 226. 143. 115.  89. 297. 233. 294. 323. 125.  90.\n",
            " 308. 118. 224. 128. 122. 214. 213. 268. 256.  84. 105. 288. 139.  78.\n",
            " 273. 242. 424. 303. 148. 160. 192. 307. 220. 447. 309.  22. 111. 261.\n",
            " 215. 234. 131. 352.  80. 239. 110. 130. 184. 252. 113. 230. 341. 255.\n",
            " 103. 238. 248. 120. 241. 269. 201. 203. 463. 176.  82. 119.  97.  96.\n",
            "  81. 116. 134.  85.  83.  87.  75.] values\n",
            "bu ---> [ 36.   18.   53.   56.   26.   25.   54.   31.   60.  107.   55.   72.\n",
            "  86.   90.  162.   46.   87.   27.  148.  180.  163.    nan  50.   75.\n",
            "  45.   28.  155.   33.   39.  153.   29.   65.  103.   70.   80.   20.\n",
            " 202.   77.   89.   24.   17.   32.  114.   66.   38.  164.  142.   96.\n",
            " 391.   15.  111.   73.   19.   92.   35.   16.  139.   48.   85.   98.\n",
            " 186.   37.   47.   52.   82.   51.  106.   22.  217.   88.  118.   50.1\n",
            "  71.   34.   40.   21.  219.   30.  125.  166.   49.  208.  176.   68.\n",
            " 145.  165.  322.   23.  235.  132.   76.   42.   44.   41.  113.    1.5\n",
            " 146.   58.  133.  137.   67.  115.  223.   98.6 158.   94.   74.  150.\n",
            "  61.   57.   95.  191.   93.  241.   64.   79.  215.  309.   10. ] values\n",
            "sc ---> [ 1.2   0.8   1.8   3.8   1.4   1.1  24.    1.9   7.2   4.    2.7   2.1\n",
            "  4.6   4.1   9.6   2.2   5.2   1.3   1.6   3.9  76.    7.7    nan  2.4\n",
            "  7.3   1.5   2.5   2.    3.4   0.7   1.   10.8   6.3   5.9   0.9   3.\n",
            "  3.25  9.7   6.4   3.2  32.    0.6   6.1   3.3   6.7   8.5   2.8  15.\n",
            "  2.9   1.7   3.6   5.6   6.5   4.4  10.2  11.5   0.5  12.2   5.3   9.2\n",
            " 13.8  16.9   6.    7.1  18.    2.3  13.   48.1  14.2  16.4   2.6   7.5\n",
            "  4.3  18.1  11.8   9.3   6.8  13.5  12.8  11.9  12.   13.4  15.2  13.3\n",
            "  0.4 ] values\n",
            "sod ---> [  nan 111.  142.  104.  114.  131.  138.  135.  130.  141.  139.    4.5\n",
            " 136.  129.  140.  132.  133.  134.  125.  163.  137.  128.  143.  127.\n",
            " 146.  126.  122.  147.  124.  115.  145.  113.  120.  150.  144. ] values\n",
            "pot ---> [ nan  2.5  3.2  4.   3.7  4.2  5.8  3.4  6.4  4.9  4.1  4.3  5.2  3.8\n",
            "  4.6  3.9  4.7  5.9  4.8  4.4  6.6 39.   5.5  5.   3.5  3.6  7.6  2.9\n",
            "  4.5  5.7  5.4  5.3 47.   6.3  5.1  5.6  3.   2.8  2.7  6.5  3.3] values\n",
            "hemo ---> [15.4 11.3  9.6 11.2 11.6 12.2 12.4 10.8  9.5  9.4  9.7  9.8  5.6  7.6\n",
            " 12.6 12.1 12.7 10.3  7.7 10.9  nan 11.1  9.9 12.5 12.9 10.1 12.  13.\n",
            "  7.9  9.3 15.  10.   8.6 13.6 10.2 10.5  6.6 11.   7.5 15.6 15.2  4.8\n",
            "  9.1  8.1 11.9 13.5  8.3  7.1 16.1 10.4  9.2  6.2 13.9 14.1  6.  11.8\n",
            " 11.7 11.4 14.   8.2 13.2  6.1  8.  12.3  8.4 14.3  9.   8.7 10.6 13.1\n",
            " 10.7  5.5  5.8  6.8  8.8  8.5 13.8 11.5  7.3 13.7 12.8 13.4  6.3  3.1\n",
            " 17.  15.9 14.5 15.5 16.2 14.4 14.2 16.3 14.8 16.5 15.7 13.3 14.6 16.4\n",
            " 16.9 16.  14.7 16.6 14.9 16.7 16.8 15.8 15.1 17.1 17.2 15.3 17.3 17.4\n",
            " 17.7 17.8 17.5 17.6] values\n",
            "pcv ---> [44. 38. 31. 32. 35. 39. 36. 33. 29. 28. nan 16. 24. 37. 30. 34. 40. 45.\n",
            " 27. 48. 52. 14. 22. 18. 42. 17. 46. 23. 19. 25. 41. 26. 15. 21. 43. 20.\n",
            " 47.  9. 49. 50. 53. 51. 54.] values\n",
            "wc ---> [ 7800.  6000.  7500.  6700.  7300.    nan  6900.  9600. 12100.  4500.\n",
            " 12200. 11000.  3800. 11400.  5300.  9200.  6200.  8300.  8400. 10300.\n",
            "  9800.  9100.  7900.  6400.  8600. 18900. 21600.  4300.  8500. 11300.\n",
            "  7200.  7700. 14600.  6300.  7100. 11800.  9400.  5500.  5800. 13200.\n",
            " 12500.  5600.  7000. 11900. 10400. 10700. 12700.  6800.  6500. 13600.\n",
            " 10200.  9000. 14900.  8200. 15200.  5000. 16300. 12400. 10500.  4200.\n",
            "  4700. 10900.  8100.  9500.  2200. 12800. 11200. 19100. 12300. 16700.\n",
            "  2600. 26400.  8800.  7400.  4900.  8000. 12000. 15700.  4100.  5700.\n",
            " 11500.  5400. 10800.  9900.  5200.  5900.  9300.  9700.  5100.  6600.] values\n",
            "rc ---> [5.2 nan 3.9 4.6 4.4 5.  4.  3.7 3.8 3.4 2.6 2.8 4.3 3.2 3.6 4.1 4.9 2.5\n",
            " 4.2 4.5 3.1 4.7 3.5 6.  2.1 5.6 2.3 2.9 2.7 8.  3.3 3.  2.4 4.8 5.4 6.1\n",
            " 6.2 6.3 5.1 5.8 5.5 5.3 6.4 5.7 5.9 6.5] values\n"
          ]
        }
      ],
      "source": [
        "\n",
        "for col in num_cols:\n",
        "  print(f\"{col} ---> {df[col].unique()} values\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ju0GUGLfuR12"
      },
      "source": [
        "# **Data Pre Processing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "wk3oWyL3_rzC"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "rbc               152\n",
              "rc                131\n",
              "wc                106\n",
              "pot                88\n",
              "sod                87\n",
              "pcv                71\n",
              "pc                 65\n",
              "hemo               52\n",
              "su                 49\n",
              "sg                 47\n",
              "al                 46\n",
              "bgr                44\n",
              "bu                 19\n",
              "sc                 17\n",
              "bp                 12\n",
              "age                 9\n",
              "ba                  4\n",
              "pcc                 4\n",
              "htn                 2\n",
              "dm                  2\n",
              "cad                 2\n",
              "appet               1\n",
              "pe                  1\n",
              "ane                 1\n",
              "classification      0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isna().sum().sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "PFo-7BbnAdXb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "age       9\n",
              "bp       12\n",
              "sg       47\n",
              "al       46\n",
              "su       49\n",
              "bgr      44\n",
              "bu       19\n",
              "sc       17\n",
              "sod      87\n",
              "pot      88\n",
              "hemo     52\n",
              "pcv      71\n",
              "wc      106\n",
              "rc      131\n",
              "dtype: int64"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[num_cols].isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVzL-83wBRCy"
      },
      "source": [
        "# **Filling Null Values for categorical data**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjN9J-3BEB0r",
        "outputId": "f15639f5-8d04-4dc8-942c-e7d05c17c91a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rbc ---> [nan 'normal' 'abnormal'] values\n",
            "pc ---> ['normal' 'abnormal' nan] values\n",
            "pcc ---> ['notpresent' 'present' nan] values\n",
            "ba ---> ['notpresent' 'present' nan] values\n",
            "htn ---> ['yes' 'no' nan] values\n",
            "dm ---> ['yes' 'no' nan] values\n",
            "cad ---> ['no' 'yes' nan] values\n",
            "appet ---> ['good' 'poor' nan] values\n",
            "pe ---> ['no' 'yes' nan] values\n",
            "ane ---> ['no' 'yes' nan] values\n",
            "classification ---> [0 1] values\n"
          ]
        }
      ],
      "source": [
        "for col in cat_cols:\n",
        "  print(f\"{col} ---> {df[col].unique()} values\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Nj3ydXn9ELTv",
        "outputId": "dcd2473d-22a8-49a4-c33d-bedba573de4e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rbc</th>\n",
              "      <th>pc</th>\n",
              "      <th>pcc</th>\n",
              "      <th>ba</th>\n",
              "      <th>htn</th>\n",
              "      <th>dm</th>\n",
              "      <th>cad</th>\n",
              "      <th>appet</th>\n",
              "      <th>pe</th>\n",
              "      <th>ane</th>\n",
              "      <th>classification</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>normal</td>\n",
              "      <td>normal</td>\n",
              "      <td>notpresent</td>\n",
              "      <td>notpresent</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>good</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>normal</td>\n",
              "      <td>normal</td>\n",
              "      <td>notpresent</td>\n",
              "      <td>notpresent</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>good</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>normal</td>\n",
              "      <td>normal</td>\n",
              "      <td>notpresent</td>\n",
              "      <td>notpresent</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>poor</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>normal</td>\n",
              "      <td>abnormal</td>\n",
              "      <td>present</td>\n",
              "      <td>notpresent</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>poor</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>normal</td>\n",
              "      <td>normal</td>\n",
              "      <td>notpresent</td>\n",
              "      <td>notpresent</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>good</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>normal</td>\n",
              "      <td>normal</td>\n",
              "      <td>notpresent</td>\n",
              "      <td>notpresent</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>good</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>normal</td>\n",
              "      <td>normal</td>\n",
              "      <td>notpresent</td>\n",
              "      <td>notpresent</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>good</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>normal</td>\n",
              "      <td>normal</td>\n",
              "      <td>notpresent</td>\n",
              "      <td>notpresent</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>good</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>398</th>\n",
              "      <td>normal</td>\n",
              "      <td>normal</td>\n",
              "      <td>notpresent</td>\n",
              "      <td>notpresent</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>good</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399</th>\n",
              "      <td>normal</td>\n",
              "      <td>normal</td>\n",
              "      <td>notpresent</td>\n",
              "      <td>notpresent</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>good</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>400 rows Ã— 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        rbc        pc         pcc          ba  htn   dm cad appet   pe  ane  \\\n",
              "0    normal    normal  notpresent  notpresent  yes  yes  no  good   no   no   \n",
              "1    normal    normal  notpresent  notpresent   no   no  no  good   no   no   \n",
              "2    normal    normal  notpresent  notpresent   no  yes  no  poor   no  yes   \n",
              "3    normal  abnormal     present  notpresent  yes   no  no  poor  yes  yes   \n",
              "4    normal    normal  notpresent  notpresent   no   no  no  good   no   no   \n",
              "..      ...       ...         ...         ...  ...  ...  ..   ...  ...  ...   \n",
              "395  normal    normal  notpresent  notpresent   no   no  no  good   no   no   \n",
              "396  normal    normal  notpresent  notpresent   no   no  no  good   no   no   \n",
              "397  normal    normal  notpresent  notpresent   no   no  no  good   no   no   \n",
              "398  normal    normal  notpresent  notpresent   no   no  no  good   no   no   \n",
              "399  normal    normal  notpresent  notpresent   no   no  no  good   no   no   \n",
              "\n",
              "     classification  \n",
              "0                 0  \n",
              "1                 0  \n",
              "2                 0  \n",
              "3                 0  \n",
              "4                 0  \n",
              "..              ...  \n",
              "395               1  \n",
              "396               1  \n",
              "397               1  \n",
              "398               1  \n",
              "399               1  \n",
              "\n",
              "[400 rows x 11 columns]"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "for col in cat_cols:\n",
        "  mode = df[col].mode()[0]\n",
        "  df[col] = df[col].fillna(mode)\n",
        "\n",
        "\n",
        "df[cat_cols]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3i06mvTFrIS",
        "outputId": "8d61539e-aa0b-4931-bdf1-bf6f94a31e3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rbc ---> ['normal' 'abnormal'] values\n",
            "pc ---> ['normal' 'abnormal'] values\n",
            "pcc ---> ['notpresent' 'present'] values\n",
            "ba ---> ['notpresent' 'present'] values\n",
            "htn ---> ['yes' 'no'] values\n",
            "dm ---> ['yes' 'no'] values\n",
            "cad ---> ['no' 'yes'] values\n",
            "appet ---> ['good' 'poor'] values\n",
            "pe ---> ['no' 'yes'] values\n",
            "ane ---> ['no' 'yes'] values\n",
            "classification ---> [0 1] values\n"
          ]
        }
      ],
      "source": [
        "for col in cat_cols:\n",
        "  print(f\"{col} ---> {df[col].unique()} values\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXUh3hdOGAyF"
      },
      "source": [
        "# **Filling Null Values for Numeric Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "UIASX6rCGNAW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "age ---> [48.  7. 62. 51. 60. 68. 24. 52. 53. 50. 63. 40. 47. 61. 21. 42. 75. 69.\n",
            " nan 73. 70. 65. 76. 72. 82. 46. 45. 35. 54. 11. 59. 67. 15. 55. 44. 26.\n",
            " 64. 56.  5. 74. 38. 58. 71. 34. 17. 12. 43. 41. 57.  8. 39. 66. 81. 14.\n",
            " 27. 83. 30.  4.  3.  6. 32. 80. 49. 90. 78. 19.  2. 33. 36. 37. 23. 25.\n",
            " 20. 29. 28. 22. 79.] values\n",
            "bp ---> [ 80.  50.  70.  90.  nan 100.  60. 110. 140. 180. 120.] values\n",
            "sg ---> [1.02  1.01  1.005 1.015   nan 1.025] values\n",
            "al ---> [ 1.  4.  2.  3.  0. nan  5.] values\n",
            "su ---> [ 0.  3.  4.  1. nan  2.  5.] values\n",
            "bgr ---> [121.  nan 423. 117. 106.  74. 100. 410. 138.  70. 490. 380. 208.  98.\n",
            " 157.  76.  99. 114. 263. 173.  95. 108. 156. 264. 123.  93. 107. 159.\n",
            " 140. 171. 270.  92. 137. 204.  79. 207. 124. 144.  91. 162. 246. 253.\n",
            " 141. 182.  86. 150. 146. 425. 112. 250. 360. 163. 129. 133. 102. 158.\n",
            " 165. 132. 104. 127. 415. 169. 251. 109. 280. 210. 219. 295.  94. 172.\n",
            " 101. 298. 153.  88. 226. 143. 115.  89. 297. 233. 294. 323. 125.  90.\n",
            " 308. 118. 224. 128. 122. 214. 213. 268. 256.  84. 105. 288. 139.  78.\n",
            " 273. 242. 424. 303. 148. 160. 192. 307. 220. 447. 309.  22. 111. 261.\n",
            " 215. 234. 131. 352.  80. 239. 110. 130. 184. 252. 113. 230. 341. 255.\n",
            " 103. 238. 248. 120. 241. 269. 201. 203. 463. 176.  82. 119.  97.  96.\n",
            "  81. 116. 134.  85.  83.  87.  75.] values\n",
            "bu ---> [ 36.   18.   53.   56.   26.   25.   54.   31.   60.  107.   55.   72.\n",
            "  86.   90.  162.   46.   87.   27.  148.  180.  163.    nan  50.   75.\n",
            "  45.   28.  155.   33.   39.  153.   29.   65.  103.   70.   80.   20.\n",
            " 202.   77.   89.   24.   17.   32.  114.   66.   38.  164.  142.   96.\n",
            " 391.   15.  111.   73.   19.   92.   35.   16.  139.   48.   85.   98.\n",
            " 186.   37.   47.   52.   82.   51.  106.   22.  217.   88.  118.   50.1\n",
            "  71.   34.   40.   21.  219.   30.  125.  166.   49.  208.  176.   68.\n",
            " 145.  165.  322.   23.  235.  132.   76.   42.   44.   41.  113.    1.5\n",
            " 146.   58.  133.  137.   67.  115.  223.   98.6 158.   94.   74.  150.\n",
            "  61.   57.   95.  191.   93.  241.   64.   79.  215.  309.   10. ] values\n",
            "sc ---> [ 1.2   0.8   1.8   3.8   1.4   1.1  24.    1.9   7.2   4.    2.7   2.1\n",
            "  4.6   4.1   9.6   2.2   5.2   1.3   1.6   3.9  76.    7.7    nan  2.4\n",
            "  7.3   1.5   2.5   2.    3.4   0.7   1.   10.8   6.3   5.9   0.9   3.\n",
            "  3.25  9.7   6.4   3.2  32.    0.6   6.1   3.3   6.7   8.5   2.8  15.\n",
            "  2.9   1.7   3.6   5.6   6.5   4.4  10.2  11.5   0.5  12.2   5.3   9.2\n",
            " 13.8  16.9   6.    7.1  18.    2.3  13.   48.1  14.2  16.4   2.6   7.5\n",
            "  4.3  18.1  11.8   9.3   6.8  13.5  12.8  11.9  12.   13.4  15.2  13.3\n",
            "  0.4 ] values\n",
            "sod ---> [  nan 111.  142.  104.  114.  131.  138.  135.  130.  141.  139.    4.5\n",
            " 136.  129.  140.  132.  133.  134.  125.  163.  137.  128.  143.  127.\n",
            " 146.  126.  122.  147.  124.  115.  145.  113.  120.  150.  144. ] values\n",
            "pot ---> [ nan  2.5  3.2  4.   3.7  4.2  5.8  3.4  6.4  4.9  4.1  4.3  5.2  3.8\n",
            "  4.6  3.9  4.7  5.9  4.8  4.4  6.6 39.   5.5  5.   3.5  3.6  7.6  2.9\n",
            "  4.5  5.7  5.4  5.3 47.   6.3  5.1  5.6  3.   2.8  2.7  6.5  3.3] values\n",
            "hemo ---> [15.4 11.3  9.6 11.2 11.6 12.2 12.4 10.8  9.5  9.4  9.7  9.8  5.6  7.6\n",
            " 12.6 12.1 12.7 10.3  7.7 10.9  nan 11.1  9.9 12.5 12.9 10.1 12.  13.\n",
            "  7.9  9.3 15.  10.   8.6 13.6 10.2 10.5  6.6 11.   7.5 15.6 15.2  4.8\n",
            "  9.1  8.1 11.9 13.5  8.3  7.1 16.1 10.4  9.2  6.2 13.9 14.1  6.  11.8\n",
            " 11.7 11.4 14.   8.2 13.2  6.1  8.  12.3  8.4 14.3  9.   8.7 10.6 13.1\n",
            " 10.7  5.5  5.8  6.8  8.8  8.5 13.8 11.5  7.3 13.7 12.8 13.4  6.3  3.1\n",
            " 17.  15.9 14.5 15.5 16.2 14.4 14.2 16.3 14.8 16.5 15.7 13.3 14.6 16.4\n",
            " 16.9 16.  14.7 16.6 14.9 16.7 16.8 15.8 15.1 17.1 17.2 15.3 17.3 17.4\n",
            " 17.7 17.8 17.5 17.6] values\n",
            "pcv ---> [44. 38. 31. 32. 35. 39. 36. 33. 29. 28. nan 16. 24. 37. 30. 34. 40. 45.\n",
            " 27. 48. 52. 14. 22. 18. 42. 17. 46. 23. 19. 25. 41. 26. 15. 21. 43. 20.\n",
            " 47.  9. 49. 50. 53. 51. 54.] values\n",
            "wc ---> [ 7800.  6000.  7500.  6700.  7300.    nan  6900.  9600. 12100.  4500.\n",
            " 12200. 11000.  3800. 11400.  5300.  9200.  6200.  8300.  8400. 10300.\n",
            "  9800.  9100.  7900.  6400.  8600. 18900. 21600.  4300.  8500. 11300.\n",
            "  7200.  7700. 14600.  6300.  7100. 11800.  9400.  5500.  5800. 13200.\n",
            " 12500.  5600.  7000. 11900. 10400. 10700. 12700.  6800.  6500. 13600.\n",
            " 10200.  9000. 14900.  8200. 15200.  5000. 16300. 12400. 10500.  4200.\n",
            "  4700. 10900.  8100.  9500.  2200. 12800. 11200. 19100. 12300. 16700.\n",
            "  2600. 26400.  8800.  7400.  4900.  8000. 12000. 15700.  4100.  5700.\n",
            " 11500.  5400. 10800.  9900.  5200.  5900.  9300.  9700.  5100.  6600.] values\n",
            "rc ---> [5.2 nan 3.9 4.6 4.4 5.  4.  3.7 3.8 3.4 2.6 2.8 4.3 3.2 3.6 4.1 4.9 2.5\n",
            " 4.2 4.5 3.1 4.7 3.5 6.  2.1 5.6 2.3 2.9 2.7 8.  3.3 3.  2.4 4.8 5.4 6.1\n",
            " 6.2 6.3 5.1 5.8 5.5 5.3 6.4 5.7 5.9 6.5] values\n"
          ]
        }
      ],
      "source": [
        "for col in num_cols:\n",
        "  print(f\"{col} ---> {df[col].unique()} values\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "734JP25MGS_M",
        "outputId": "cc45121e-5946-430a-f7d0-64cc7535318e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "age       9\n",
              "bp       12\n",
              "sg       47\n",
              "al       46\n",
              "su       49\n",
              "bgr      44\n",
              "bu       19\n",
              "sc       17\n",
              "sod      87\n",
              "pot      88\n",
              "hemo     52\n",
              "pcv      71\n",
              "wc      106\n",
              "rc      131\n",
              "dtype: int64"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[num_cols].isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ltsGNA4UcAK",
        "outputId": "7a21bf4f-1493-4b00-ab5d-1fa5734dfba3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "51.48337595907928"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['age'].mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "akhYFydUHTBF"
      },
      "outputs": [],
      "source": [
        "for col in num_cols:\n",
        "  mean_sample = df[col].mean()\n",
        "  df.loc[df[col].isnull(),col] = mean_sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "mkZC42yrUrvO"
      },
      "outputs": [],
      "source": [
        "#df[num_cols].isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPzEGGodTHMB",
        "outputId": "62814efa-2aff-4211-c82c-4e0a5a2995c3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "51.483375959079275"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['age'].mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVQJzT9PJVOV",
        "outputId": "58b40779-aa7a-4b44-f85a-577c1817f238"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 400 entries, 0 to 399\n",
            "Data columns (total 14 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   age     400 non-null    float64\n",
            " 1   bp      400 non-null    float64\n",
            " 2   sg      400 non-null    float64\n",
            " 3   al      400 non-null    float64\n",
            " 4   su      400 non-null    float64\n",
            " 5   bgr     400 non-null    float64\n",
            " 6   bu      400 non-null    float64\n",
            " 7   sc      400 non-null    float64\n",
            " 8   sod     400 non-null    float64\n",
            " 9   pot     400 non-null    float64\n",
            " 10  hemo    400 non-null    float64\n",
            " 11  pcv     400 non-null    float64\n",
            " 12  wc      400 non-null    float64\n",
            " 13  rc      400 non-null    float64\n",
            "dtypes: float64(14)\n",
            "memory usage: 43.9 KB\n"
          ]
        }
      ],
      "source": [
        "df[num_cols].info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXJ1aJATWAmC"
      },
      "source": [
        "# **Feature Encoding**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lq4EcdoAKE8_",
        "outputId": "58a4fd82-bc41-4312-a433-f66ea54800be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rbc has ['normal' 'abnormal'] categories \n",
            "\n",
            "rbc has 2 categories \n",
            "\n",
            "pc has ['normal' 'abnormal'] categories \n",
            "\n",
            "pc has 2 categories \n",
            "\n",
            "pcc has ['notpresent' 'present'] categories \n",
            "\n",
            "pcc has 2 categories \n",
            "\n",
            "ba has ['notpresent' 'present'] categories \n",
            "\n",
            "ba has 2 categories \n",
            "\n",
            "htn has ['yes' 'no'] categories \n",
            "\n",
            "htn has 2 categories \n",
            "\n",
            "dm has ['yes' 'no'] categories \n",
            "\n",
            "dm has 2 categories \n",
            "\n",
            "cad has ['no' 'yes'] categories \n",
            "\n",
            "cad has 2 categories \n",
            "\n",
            "appet has ['good' 'poor'] categories \n",
            "\n",
            "appet has 2 categories \n",
            "\n",
            "pe has ['no' 'yes'] categories \n",
            "\n",
            "pe has 2 categories \n",
            "\n",
            "ane has ['no' 'yes'] categories \n",
            "\n",
            "ane has 2 categories \n",
            "\n",
            "classification has [0 1] categories \n",
            "\n",
            "classification has 2 categories \n",
            "\n"
          ]
        }
      ],
      "source": [
        "for col in cat_cols:\n",
        "  print(\"{} has {} categories \\n\" .format(col,df[col].unique()))\n",
        "  print(\"{} has {} categories \\n\" .format(col,df[col].nunique()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "48dX3gf8Wk5E"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le_obj = LabelEncoder()\n",
        "\n",
        "for col in cat_cols:\n",
        "  df[col] = le_obj.fit_transform(df[col])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBcQap_nXO4E",
        "outputId": "06e4df62-54ef-44a7-ab6c-2f180dd73d29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rbc has [1 0] categories \n",
            "\n",
            "pc has [1 0] categories \n",
            "\n",
            "pcc has [0 1] categories \n",
            "\n",
            "ba has [0 1] categories \n",
            "\n",
            "htn has [1 0] categories \n",
            "\n",
            "dm has [1 0] categories \n",
            "\n",
            "cad has [0 1] categories \n",
            "\n",
            "appet has [0 1] categories \n",
            "\n",
            "pe has [0 1] categories \n",
            "\n",
            "ane has [0 1] categories \n",
            "\n",
            "classification has [0 1] categories \n",
            "\n"
          ]
        }
      ],
      "source": [
        "for col in cat_cols:\n",
        "  print(\"{} has {} categories \\n\" .format(col,df[col].unique()))\n",
        " # print(\"{} has {} categories \\n\" .format(col,df[col].nunique()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwRYdzdeXhUr",
        "outputId": "538ddf6d-e04b-4303-baff-d5a21655e0d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 400 entries, 0 to 399\n",
            "Data columns (total 11 columns):\n",
            " #   Column          Non-Null Count  Dtype\n",
            "---  ------          --------------  -----\n",
            " 0   rbc             400 non-null    int32\n",
            " 1   pc              400 non-null    int32\n",
            " 2   pcc             400 non-null    int32\n",
            " 3   ba              400 non-null    int32\n",
            " 4   htn             400 non-null    int32\n",
            " 5   dm              400 non-null    int32\n",
            " 6   cad             400 non-null    int32\n",
            " 7   appet           400 non-null    int32\n",
            " 8   pe              400 non-null    int32\n",
            " 9   ane             400 non-null    int32\n",
            " 10  classification  400 non-null    int64\n",
            "dtypes: int32(10), int64(1)\n",
            "memory usage: 18.9 KB\n"
          ]
        }
      ],
      "source": [
        "df[cat_cols].info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQD7zeBsGK05"
      },
      "source": [
        "# **Build the Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aQeTkukXxPH"
      },
      "source": [
        "**Classify input Features and target feature**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hh3ntcIfX54c",
        "outputId": "3155e30e-b77e-427e-c721-72bd0fabbc58"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['age', 'bp', 'sg', 'al', 'su', 'rbc', 'pc', 'pcc', 'ba', 'bgr', 'bu',\n",
              "       'sc', 'sod', 'pot', 'hemo', 'pcv', 'wc', 'rc', 'htn', 'dm', 'cad',\n",
              "       'appet', 'pe', 'ane', 'classification'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIFtqLZTX_sr",
        "outputId": "abef5b99-9733-4a5d-a025-bad5ddd8f17e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "z0bltFX2YtMe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0      0\n",
              "1      0\n",
              "2      0\n",
              "3      0\n",
              "4      0\n",
              "      ..\n",
              "395    1\n",
              "396    1\n",
              "397    1\n",
              "398    1\n",
              "399    1\n",
              "Name: classification, Length: 400, dtype: int64"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['classification']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "Eypez-fYYD6u"
      },
      "outputs": [],
      "source": [
        "input_col = df.columns[0:24]\n",
        "target_col = 'classification'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "f9wri0N3ZYhE"
      },
      "outputs": [],
      "source": [
        "X = df[input_col]\n",
        "Y = df[target_col]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "O8LF5H0bYzma"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, Y_train,Y_test = train_test_split(\n",
        "    X,\n",
        "    Y,\n",
        "    test_size = 0.30,\n",
        "    random_state=1\n",
        "\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "yZ4mXjWFZ3un",
        "outputId": "fda89f79-7c31-439e-de72-615b98adbc49"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bp</th>\n",
              "      <th>sg</th>\n",
              "      <th>al</th>\n",
              "      <th>su</th>\n",
              "      <th>rbc</th>\n",
              "      <th>pc</th>\n",
              "      <th>pcc</th>\n",
              "      <th>ba</th>\n",
              "      <th>bgr</th>\n",
              "      <th>...</th>\n",
              "      <th>hemo</th>\n",
              "      <th>pcv</th>\n",
              "      <th>wc</th>\n",
              "      <th>rc</th>\n",
              "      <th>htn</th>\n",
              "      <th>dm</th>\n",
              "      <th>cad</th>\n",
              "      <th>appet</th>\n",
              "      <th>pe</th>\n",
              "      <th>ane</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>82.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>1.010000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>9800.000000</td>\n",
              "      <td>4.200000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>34.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>1.020000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>139.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>12.700000</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>2200.000000</td>\n",
              "      <td>4.707435</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>383</th>\n",
              "      <td>80.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>1.025000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>119.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>13.900000</td>\n",
              "      <td>49.000000</td>\n",
              "      <td>5100.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221</th>\n",
              "      <td>66.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>1.020000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>248.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>12.526437</td>\n",
              "      <td>38.884498</td>\n",
              "      <td>8406.122449</td>\n",
              "      <td>4.707435</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>351</th>\n",
              "      <td>29.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>1.020000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>83.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>17.500000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>9900.000000</td>\n",
              "      <td>4.700000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>255</th>\n",
              "      <td>34.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>1.025000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>121.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>13.600000</td>\n",
              "      <td>52.000000</td>\n",
              "      <td>9200.000000</td>\n",
              "      <td>6.300000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>64.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>1.010000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>148.036517</td>\n",
              "      <td>...</td>\n",
              "      <td>10.300000</td>\n",
              "      <td>38.884498</td>\n",
              "      <td>8406.122449</td>\n",
              "      <td>4.707435</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>42.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>1.025000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>16.500000</td>\n",
              "      <td>54.000000</td>\n",
              "      <td>7800.000000</td>\n",
              "      <td>6.200000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>235</th>\n",
              "      <td>45.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>1.010000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>113.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>7.900000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>5700.000000</td>\n",
              "      <td>4.707435</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>72.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>1.017408</td>\n",
              "      <td>1.016949</td>\n",
              "      <td>0.450142</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>137.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>9.700000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>6900.000000</td>\n",
              "      <td>2.500000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>280 rows Ã— 24 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      age    bp        sg        al        su  rbc  pc  pcc  ba         bgr  \\\n",
              "39   82.0  80.0  1.010000  2.000000  2.000000    1   1    0   0  140.000000   \n",
              "167  34.0  70.0  1.020000  0.000000  0.000000    0   1    0   0  139.000000   \n",
              "383  80.0  80.0  1.025000  0.000000  0.000000    1   1    0   0  119.000000   \n",
              "221  66.0  70.0  1.020000  1.000000  0.000000    1   1    0   0  248.000000   \n",
              "351  29.0  80.0  1.020000  0.000000  0.000000    1   1    0   0   83.000000   \n",
              "..    ...   ...       ...       ...       ...  ...  ..  ...  ..         ...   \n",
              "255  34.0  80.0  1.025000  0.000000  0.000000    1   1    0   0  121.000000   \n",
              "72   64.0  90.0  1.010000  3.000000  3.000000    1   0    1   0  148.036517   \n",
              "396  42.0  70.0  1.025000  0.000000  0.000000    1   1    0   0   75.000000   \n",
              "235  45.0  70.0  1.010000  2.000000  0.000000    1   1    0   0  113.000000   \n",
              "37   72.0  80.0  1.017408  1.016949  0.450142    1   1    0   0  137.000000   \n",
              "\n",
              "     ...       hemo        pcv           wc        rc  htn  dm  cad  appet  \\\n",
              "39   ...  13.000000  40.000000  9800.000000  4.200000    1   1    0      0   \n",
              "167  ...  12.700000  42.000000  2200.000000  4.707435    0   0    0      1   \n",
              "383  ...  13.900000  49.000000  5100.000000  5.000000    0   0    0      0   \n",
              "221  ...  12.526437  38.884498  8406.122449  4.707435    1   1    0      0   \n",
              "351  ...  17.500000  40.000000  9900.000000  4.700000    0   0    0      0   \n",
              "..   ...        ...        ...          ...       ...  ...  ..  ...    ...   \n",
              "255  ...  13.600000  52.000000  9200.000000  6.300000    0   0    0      0   \n",
              "72   ...  10.300000  38.884498  8406.122449  4.707435    1   1    0      0   \n",
              "396  ...  16.500000  54.000000  7800.000000  6.200000    0   0    0      0   \n",
              "235  ...   7.900000  26.000000  5700.000000  4.707435    0   0    1      0   \n",
              "37   ...   9.700000  28.000000  6900.000000  2.500000    1   1    0      1   \n",
              "\n",
              "     pe  ane  \n",
              "39    0    0  \n",
              "167   0    0  \n",
              "383   0    0  \n",
              "221   0    0  \n",
              "351   0    0  \n",
              "..   ..  ...  \n",
              "255   0    0  \n",
              "72    1    0  \n",
              "396   0    0  \n",
              "235   0    1  \n",
              "37    0    1  \n",
              "\n",
              "[280 rows x 24 columns]"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "d8nNm202Z6S9",
        "outputId": "084c9e3c-31bf-4fd8-9f47-55e57d98cd2d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bp</th>\n",
              "      <th>sg</th>\n",
              "      <th>al</th>\n",
              "      <th>su</th>\n",
              "      <th>rbc</th>\n",
              "      <th>pc</th>\n",
              "      <th>pcc</th>\n",
              "      <th>ba</th>\n",
              "      <th>bgr</th>\n",
              "      <th>...</th>\n",
              "      <th>hemo</th>\n",
              "      <th>pcv</th>\n",
              "      <th>wc</th>\n",
              "      <th>rc</th>\n",
              "      <th>htn</th>\n",
              "      <th>dm</th>\n",
              "      <th>cad</th>\n",
              "      <th>appet</th>\n",
              "      <th>pe</th>\n",
              "      <th>ane</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>398</th>\n",
              "      <td>17.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>1.025000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>114.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>14.200000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>7200.000000</td>\n",
              "      <td>5.900000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>72.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>1.017408</td>\n",
              "      <td>1.016949</td>\n",
              "      <td>0.450142</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>308.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>12.526437</td>\n",
              "      <td>38.884498</td>\n",
              "      <td>8406.122449</td>\n",
              "      <td>4.707435</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>328</th>\n",
              "      <td>28.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>1.020000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>131.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>12.526437</td>\n",
              "      <td>45.000000</td>\n",
              "      <td>8600.000000</td>\n",
              "      <td>6.500000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>339</th>\n",
              "      <td>25.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>1.020000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>13.300000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>7000.000000</td>\n",
              "      <td>4.900000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>62.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>1.010000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>309.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>10.600000</td>\n",
              "      <td>34.000000</td>\n",
              "      <td>12800.000000</td>\n",
              "      <td>4.900000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>56.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>1.015000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>210.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>16.100000</td>\n",
              "      <td>52.000000</td>\n",
              "      <td>12500.000000</td>\n",
              "      <td>5.600000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>322</th>\n",
              "      <td>70.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>1.017408</td>\n",
              "      <td>1.016949</td>\n",
              "      <td>0.450142</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>4500.000000</td>\n",
              "      <td>4.900000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248</th>\n",
              "      <td>59.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>1.010000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>424.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>12.600000</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>10200.000000</td>\n",
              "      <td>4.100000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>186</th>\n",
              "      <td>8.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1.020000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>148.036517</td>\n",
              "      <td>...</td>\n",
              "      <td>12.526437</td>\n",
              "      <td>38.884498</td>\n",
              "      <td>8406.122449</td>\n",
              "      <td>4.707435</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>55.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>1.020000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>15.700000</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>6700.000000</td>\n",
              "      <td>4.900000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>120 rows Ã— 24 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      age    bp        sg        al        su  rbc  pc  pcc  ba         bgr  \\\n",
              "398  17.0  60.0  1.025000  0.000000  0.000000    1   1    0   0  114.000000   \n",
              "125  72.0  90.0  1.017408  1.016949  0.450142    1   1    0   0  308.000000   \n",
              "328  28.0  70.0  1.020000  0.000000  0.000000    1   1    0   0  131.000000   \n",
              "339  25.0  70.0  1.020000  0.000000  0.000000    1   1    0   0   88.000000   \n",
              "172  62.0  80.0  1.010000  1.000000  2.000000    1   1    0   0  309.000000   \n",
              "..    ...   ...       ...       ...       ...  ...  ..  ...  ..         ...   \n",
              "91   56.0  70.0  1.015000  4.000000  1.000000    0   1    0   0  210.000000   \n",
              "322  70.0  60.0  1.017408  1.016949  0.450142    1   1    0   0  120.000000   \n",
              "248  59.0  70.0  1.010000  1.000000  3.000000    0   0    0   0  424.000000   \n",
              "186   8.0  50.0  1.020000  4.000000  0.000000    1   1    0   0  148.036517   \n",
              "395  55.0  80.0  1.020000  0.000000  0.000000    1   1    0   0  140.000000   \n",
              "\n",
              "     ...       hemo        pcv            wc        rc  htn  dm  cad  appet  \\\n",
              "398  ...  14.200000  51.000000   7200.000000  5.900000    0   0    0      0   \n",
              "125  ...  12.526437  38.884498   8406.122449  4.707435    1   1    0      1   \n",
              "328  ...  12.526437  45.000000   8600.000000  6.500000    0   0    0      0   \n",
              "339  ...  13.300000  48.000000   7000.000000  4.900000    0   0    0      0   \n",
              "172  ...  10.600000  34.000000  12800.000000  4.900000    0   0    0      0   \n",
              "..   ...        ...        ...           ...       ...  ...  ..  ...    ...   \n",
              "91   ...  16.100000  52.000000  12500.000000  5.600000    0   0    0      0   \n",
              "322  ...  16.000000  43.000000   4500.000000  4.900000    0   0    0      0   \n",
              "248  ...  12.600000  37.000000  10200.000000  4.100000    1   1    1      0   \n",
              "186  ...  12.526437  38.884498   8406.122449  4.707435    0   0    0      0   \n",
              "395  ...  15.700000  47.000000   6700.000000  4.900000    0   0    0      0   \n",
              "\n",
              "     pe  ane  \n",
              "398   0    0  \n",
              "125   0    0  \n",
              "328   0    0  \n",
              "339   0    0  \n",
              "172   0    0  \n",
              "..   ..  ...  \n",
              "91    0    0  \n",
              "322   0    0  \n",
              "248   0    0  \n",
              "186   1    0  \n",
              "395   0    0  \n",
              "\n",
              "[120 rows x 24 columns]"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9i8x3HgrZ9PI",
        "outputId": "e8c9a6f8-a7ec-4998-ca25-4fc15aeb1203"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "39     0\n",
              "167    0\n",
              "383    1\n",
              "221    0\n",
              "351    1\n",
              "      ..\n",
              "255    1\n",
              "72     0\n",
              "396    1\n",
              "235    0\n",
              "37     0\n",
              "Name: classification, Length: 280, dtype: int64"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPBtPB7mZ_dd",
        "outputId": "3e400eb6-09bc-499d-d603-4988530e3189"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "398    1\n",
              "125    0\n",
              "328    1\n",
              "339    1\n",
              "172    0\n",
              "      ..\n",
              "91     0\n",
              "322    1\n",
              "248    0\n",
              "186    0\n",
              "395    1\n",
              "Name: classification, Length: 120, dtype: int64"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJe5ww5LJLHP"
      },
      "source": [
        "# **Decision Tree Classifier**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHMbrmnOJhGh"
      },
      "source": [
        "**Neccesary imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "PdVvMQzZaFbf"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix , classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "kMzJZzyxJ1Lu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on class DecisionTreeClassifier in module sklearn.tree._classes:\n",
            "\n",
            "class DecisionTreeClassifier(sklearn.base.ClassifierMixin, BaseDecisionTree)\n",
            " |  DecisionTreeClassifier(*, criterion='gini', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, class_weight=None, ccp_alpha=0.0)\n",
            " |  \n",
            " |  A decision tree classifier.\n",
            " |  \n",
            " |  Read more in the :ref:`User Guide <tree>`.\n",
            " |  \n",
            " |  Parameters\n",
            " |  ----------\n",
            " |  criterion : {\"gini\", \"entropy\", \"log_loss\"}, default=\"gini\"\n",
            " |      The function to measure the quality of a split. Supported criteria are\n",
            " |      \"gini\" for the Gini impurity and \"log_loss\" and \"entropy\" both for the\n",
            " |      Shannon information gain, see :ref:`tree_mathematical_formulation`.\n",
            " |  \n",
            " |  splitter : {\"best\", \"random\"}, default=\"best\"\n",
            " |      The strategy used to choose the split at each node. Supported\n",
            " |      strategies are \"best\" to choose the best split and \"random\" to choose\n",
            " |      the best random split.\n",
            " |  \n",
            " |  max_depth : int, default=None\n",
            " |      The maximum depth of the tree. If None, then nodes are expanded until\n",
            " |      all leaves are pure or until all leaves contain less than\n",
            " |      min_samples_split samples.\n",
            " |  \n",
            " |  min_samples_split : int or float, default=2\n",
            " |      The minimum number of samples required to split an internal node:\n",
            " |  \n",
            " |      - If int, then consider `min_samples_split` as the minimum number.\n",
            " |      - If float, then `min_samples_split` is a fraction and\n",
            " |        `ceil(min_samples_split * n_samples)` are the minimum\n",
            " |        number of samples for each split.\n",
            " |  \n",
            " |      .. versionchanged:: 0.18\n",
            " |         Added float values for fractions.\n",
            " |  \n",
            " |  min_samples_leaf : int or float, default=1\n",
            " |      The minimum number of samples required to be at a leaf node.\n",
            " |      A split point at any depth will only be considered if it leaves at\n",
            " |      least ``min_samples_leaf`` training samples in each of the left and\n",
            " |      right branches.  This may have the effect of smoothing the model,\n",
            " |      especially in regression.\n",
            " |  \n",
            " |      - If int, then consider `min_samples_leaf` as the minimum number.\n",
            " |      - If float, then `min_samples_leaf` is a fraction and\n",
            " |        `ceil(min_samples_leaf * n_samples)` are the minimum\n",
            " |        number of samples for each node.\n",
            " |  \n",
            " |      .. versionchanged:: 0.18\n",
            " |         Added float values for fractions.\n",
            " |  \n",
            " |  min_weight_fraction_leaf : float, default=0.0\n",
            " |      The minimum weighted fraction of the sum total of weights (of all\n",
            " |      the input samples) required to be at a leaf node. Samples have\n",
            " |      equal weight when sample_weight is not provided.\n",
            " |  \n",
            " |  max_features : int, float or {\"auto\", \"sqrt\", \"log2\"}, default=None\n",
            " |      The number of features to consider when looking for the best split:\n",
            " |  \n",
            " |          - If int, then consider `max_features` features at each split.\n",
            " |          - If float, then `max_features` is a fraction and\n",
            " |            `max(1, int(max_features * n_features_in_))` features are considered at\n",
            " |            each split.\n",
            " |          - If \"sqrt\", then `max_features=sqrt(n_features)`.\n",
            " |          - If \"log2\", then `max_features=log2(n_features)`.\n",
            " |          - If None, then `max_features=n_features`.\n",
            " |  \n",
            " |      Note: the search for a split does not stop until at least one\n",
            " |      valid partition of the node samples is found, even if it requires to\n",
            " |      effectively inspect more than ``max_features`` features.\n",
            " |  \n",
            " |  random_state : int, RandomState instance or None, default=None\n",
            " |      Controls the randomness of the estimator. The features are always\n",
            " |      randomly permuted at each split, even if ``splitter`` is set to\n",
            " |      ``\"best\"``. When ``max_features < n_features``, the algorithm will\n",
            " |      select ``max_features`` at random at each split before finding the best\n",
            " |      split among them. But the best found split may vary across different\n",
            " |      runs, even if ``max_features=n_features``. That is the case, if the\n",
            " |      improvement of the criterion is identical for several splits and one\n",
            " |      split has to be selected at random. To obtain a deterministic behaviour\n",
            " |      during fitting, ``random_state`` has to be fixed to an integer.\n",
            " |      See :term:`Glossary <random_state>` for details.\n",
            " |  \n",
            " |  max_leaf_nodes : int, default=None\n",
            " |      Grow a tree with ``max_leaf_nodes`` in best-first fashion.\n",
            " |      Best nodes are defined as relative reduction in impurity.\n",
            " |      If None then unlimited number of leaf nodes.\n",
            " |  \n",
            " |  min_impurity_decrease : float, default=0.0\n",
            " |      A node will be split if this split induces a decrease of the impurity\n",
            " |      greater than or equal to this value.\n",
            " |  \n",
            " |      The weighted impurity decrease equation is the following::\n",
            " |  \n",
            " |          N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
            " |                              - N_t_L / N_t * left_impurity)\n",
            " |  \n",
            " |      where ``N`` is the total number of samples, ``N_t`` is the number of\n",
            " |      samples at the current node, ``N_t_L`` is the number of samples in the\n",
            " |      left child, and ``N_t_R`` is the number of samples in the right child.\n",
            " |  \n",
            " |      ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
            " |      if ``sample_weight`` is passed.\n",
            " |  \n",
            " |      .. versionadded:: 0.19\n",
            " |  \n",
            " |  class_weight : dict, list of dict or \"balanced\", default=None\n",
            " |      Weights associated with classes in the form ``{class_label: weight}``.\n",
            " |      If None, all classes are supposed to have weight one. For\n",
            " |      multi-output problems, a list of dicts can be provided in the same\n",
            " |      order as the columns of y.\n",
            " |  \n",
            " |      Note that for multioutput (including multilabel) weights should be\n",
            " |      defined for each class of every column in its own dict. For example,\n",
            " |      for four-class multilabel classification weights should be\n",
            " |      [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of\n",
            " |      [{1:1}, {2:5}, {3:1}, {4:1}].\n",
            " |  \n",
            " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
            " |      weights inversely proportional to class frequencies in the input data\n",
            " |      as ``n_samples / (n_classes * np.bincount(y))``\n",
            " |  \n",
            " |      For multi-output, the weights of each column of y will be multiplied.\n",
            " |  \n",
            " |      Note that these weights will be multiplied with sample_weight (passed\n",
            " |      through the fit method) if sample_weight is specified.\n",
            " |  \n",
            " |  ccp_alpha : non-negative float, default=0.0\n",
            " |      Complexity parameter used for Minimal Cost-Complexity Pruning. The\n",
            " |      subtree with the largest cost complexity that is smaller than\n",
            " |      ``ccp_alpha`` will be chosen. By default, no pruning is performed. See\n",
            " |      :ref:`minimal_cost_complexity_pruning` for details.\n",
            " |  \n",
            " |      .. versionadded:: 0.22\n",
            " |  \n",
            " |  Attributes\n",
            " |  ----------\n",
            " |  classes_ : ndarray of shape (n_classes,) or list of ndarray\n",
            " |      The classes labels (single output problem),\n",
            " |      or a list of arrays of class labels (multi-output problem).\n",
            " |  \n",
            " |  feature_importances_ : ndarray of shape (n_features,)\n",
            " |      The impurity-based feature importances.\n",
            " |      The higher, the more important the feature.\n",
            " |      The importance of a feature is computed as the (normalized)\n",
            " |      total reduction of the criterion brought by that feature.  It is also\n",
            " |      known as the Gini importance [4]_.\n",
            " |  \n",
            " |      Warning: impurity-based feature importances can be misleading for\n",
            " |      high cardinality features (many unique values). See\n",
            " |      :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
            " |  \n",
            " |  max_features_ : int\n",
            " |      The inferred value of max_features.\n",
            " |  \n",
            " |  n_classes_ : int or list of int\n",
            " |      The number of classes (for single output problems),\n",
            " |      or a list containing the number of classes for each\n",
            " |      output (for multi-output problems).\n",
            " |  \n",
            " |  n_features_in_ : int\n",
            " |      Number of features seen during :term:`fit`.\n",
            " |  \n",
            " |      .. versionadded:: 0.24\n",
            " |  \n",
            " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
            " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
            " |      has feature names that are all strings.\n",
            " |  \n",
            " |      .. versionadded:: 1.0\n",
            " |  \n",
            " |  n_outputs_ : int\n",
            " |      The number of outputs when ``fit`` is performed.\n",
            " |  \n",
            " |  tree_ : Tree instance\n",
            " |      The underlying Tree object. Please refer to\n",
            " |      ``help(sklearn.tree._tree.Tree)`` for attributes of Tree object and\n",
            " |      :ref:`sphx_glr_auto_examples_tree_plot_unveil_tree_structure.py`\n",
            " |      for basic usage of these attributes.\n",
            " |  \n",
            " |  See Also\n",
            " |  --------\n",
            " |  DecisionTreeRegressor : A decision tree regressor.\n",
            " |  \n",
            " |  Notes\n",
            " |  -----\n",
            " |  The default values for the parameters controlling the size of the trees\n",
            " |  (e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\n",
            " |  unpruned trees which can potentially be very large on some data sets. To\n",
            " |  reduce memory consumption, the complexity and size of the trees should be\n",
            " |  controlled by setting those parameter values.\n",
            " |  \n",
            " |  The :meth:`predict` method operates using the :func:`numpy.argmax`\n",
            " |  function on the outputs of :meth:`predict_proba`. This means that in\n",
            " |  case the highest predicted probabilities are tied, the classifier will\n",
            " |  predict the tied class with the lowest index in :term:`classes_`.\n",
            " |  \n",
            " |  References\n",
            " |  ----------\n",
            " |  \n",
            " |  .. [1] https://en.wikipedia.org/wiki/Decision_tree_learning\n",
            " |  \n",
            " |  .. [2] L. Breiman, J. Friedman, R. Olshen, and C. Stone, \"Classification\n",
            " |         and Regression Trees\", Wadsworth, Belmont, CA, 1984.\n",
            " |  \n",
            " |  .. [3] T. Hastie, R. Tibshirani and J. Friedman. \"Elements of Statistical\n",
            " |         Learning\", Springer, 2009.\n",
            " |  \n",
            " |  .. [4] L. Breiman, and A. Cutler, \"Random Forests\",\n",
            " |         https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm\n",
            " |  \n",
            " |  Examples\n",
            " |  --------\n",
            " |  >>> from sklearn.datasets import load_iris\n",
            " |  >>> from sklearn.model_selection import cross_val_score\n",
            " |  >>> from sklearn.tree import DecisionTreeClassifier\n",
            " |  >>> clf = DecisionTreeClassifier(random_state=0)\n",
            " |  >>> iris = load_iris()\n",
            " |  >>> cross_val_score(clf, iris.data, iris.target, cv=10)\n",
            " |  ...                             # doctest: +SKIP\n",
            " |  ...\n",
            " |  array([ 1.     ,  0.93...,  0.86...,  0.93...,  0.93...,\n",
            " |          0.93...,  0.93...,  1.     ,  0.93...,  1.      ])\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      DecisionTreeClassifier\n",
            " |      sklearn.base.ClassifierMixin\n",
            " |      BaseDecisionTree\n",
            " |      sklearn.base.MultiOutputMixin\n",
            " |      sklearn.base.BaseEstimator\n",
            " |      sklearn.utils._metadata_requests._MetadataRequester\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, *, criterion='gini', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, class_weight=None, ccp_alpha=0.0)\n",
            " |      Initialize self.  See help(type(self)) for accurate signature.\n",
            " |  \n",
            " |  fit(self, X, y, sample_weight=None, check_input=True)\n",
            " |      Build a decision tree classifier from the training set (X, y).\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
            " |          The training input samples. Internally, it will be converted to\n",
            " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
            " |          to a sparse ``csc_matrix``.\n",
            " |      \n",
            " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
            " |          The target values (class labels) as integers or strings.\n",
            " |      \n",
            " |      sample_weight : array-like of shape (n_samples,), default=None\n",
            " |          Sample weights. If None, then samples are equally weighted. Splits\n",
            " |          that would create child nodes with net zero or negative weight are\n",
            " |          ignored while searching for a split in each node. Splits are also\n",
            " |          ignored if they would result in any single class carrying a\n",
            " |          negative weight in either child node.\n",
            " |      \n",
            " |      check_input : bool, default=True\n",
            " |          Allow to bypass several input checking.\n",
            " |          Don't use this parameter unless you know what you're doing.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : DecisionTreeClassifier\n",
            " |          Fitted estimator.\n",
            " |  \n",
            " |  predict_log_proba(self, X)\n",
            " |      Predict class log-probabilities of the input samples X.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
            " |          The input samples. Internally, it will be converted to\n",
            " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
            " |          to a sparse ``csr_matrix``.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      proba : ndarray of shape (n_samples, n_classes) or list of n_outputs             such arrays if n_outputs > 1\n",
            " |          The class log-probabilities of the input samples. The order of the\n",
            " |          classes corresponds to that in the attribute :term:`classes_`.\n",
            " |  \n",
            " |  predict_proba(self, X, check_input=True)\n",
            " |      Predict class probabilities of the input samples X.\n",
            " |      \n",
            " |      The predicted class probability is the fraction of samples of the same\n",
            " |      class in a leaf.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
            " |          The input samples. Internally, it will be converted to\n",
            " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
            " |          to a sparse ``csr_matrix``.\n",
            " |      \n",
            " |      check_input : bool, default=True\n",
            " |          Allow to bypass several input checking.\n",
            " |          Don't use this parameter unless you know what you're doing.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      proba : ndarray of shape (n_samples, n_classes) or list of n_outputs             such arrays if n_outputs > 1\n",
            " |          The class probabilities of the input samples. The order of the\n",
            " |          classes corresponds to that in the attribute :term:`classes_`.\n",
            " |  \n",
            " |  set_fit_request(self: sklearn.tree._classes.DecisionTreeClassifier, *, check_input: Union[bool, NoneType, str] = '$UNCHANGED$', sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.tree._classes.DecisionTreeClassifier\n",
            " |      Request metadata passed to the ``fit`` method.\n",
            " |      \n",
            " |      Note that this method is only relevant if\n",
            " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
            " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
            " |      mechanism works.\n",
            " |      \n",
            " |      The options for each parameter are:\n",
            " |      \n",
            " |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
            " |      \n",
            " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
            " |      \n",
            " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
            " |      \n",
            " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
            " |      \n",
            " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
            " |      existing request. This allows you to change the request for some\n",
            " |      parameters and not others.\n",
            " |      \n",
            " |      .. versionadded:: 1.3\n",
            " |      \n",
            " |      .. note::\n",
            " |          This method is only relevant if this estimator is used as a\n",
            " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
            " |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      check_input : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            " |          Metadata routing for ``check_input`` parameter in ``fit``.\n",
            " |      \n",
            " |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            " |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : object\n",
            " |          The updated object.\n",
            " |  \n",
            " |  set_predict_proba_request(self: sklearn.tree._classes.DecisionTreeClassifier, *, check_input: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.tree._classes.DecisionTreeClassifier\n",
            " |      Request metadata passed to the ``predict_proba`` method.\n",
            " |      \n",
            " |      Note that this method is only relevant if\n",
            " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
            " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
            " |      mechanism works.\n",
            " |      \n",
            " |      The options for each parameter are:\n",
            " |      \n",
            " |      - ``True``: metadata is requested, and passed to ``predict_proba`` if provided. The request is ignored if metadata is not provided.\n",
            " |      \n",
            " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``predict_proba``.\n",
            " |      \n",
            " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
            " |      \n",
            " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
            " |      \n",
            " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
            " |      existing request. This allows you to change the request for some\n",
            " |      parameters and not others.\n",
            " |      \n",
            " |      .. versionadded:: 1.3\n",
            " |      \n",
            " |      .. note::\n",
            " |          This method is only relevant if this estimator is used as a\n",
            " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
            " |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      check_input : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            " |          Metadata routing for ``check_input`` parameter in ``predict_proba``.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : object\n",
            " |          The updated object.\n",
            " |  \n",
            " |  set_predict_request(self: sklearn.tree._classes.DecisionTreeClassifier, *, check_input: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.tree._classes.DecisionTreeClassifier\n",
            " |      Request metadata passed to the ``predict`` method.\n",
            " |      \n",
            " |      Note that this method is only relevant if\n",
            " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
            " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
            " |      mechanism works.\n",
            " |      \n",
            " |      The options for each parameter are:\n",
            " |      \n",
            " |      - ``True``: metadata is requested, and passed to ``predict`` if provided. The request is ignored if metadata is not provided.\n",
            " |      \n",
            " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``predict``.\n",
            " |      \n",
            " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
            " |      \n",
            " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
            " |      \n",
            " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
            " |      existing request. This allows you to change the request for some\n",
            " |      parameters and not others.\n",
            " |      \n",
            " |      .. versionadded:: 1.3\n",
            " |      \n",
            " |      .. note::\n",
            " |          This method is only relevant if this estimator is used as a\n",
            " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
            " |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      check_input : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            " |          Metadata routing for ``check_input`` parameter in ``predict``.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : object\n",
            " |          The updated object.\n",
            " |  \n",
            " |  set_score_request(self: sklearn.tree._classes.DecisionTreeClassifier, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.tree._classes.DecisionTreeClassifier\n",
            " |      Request metadata passed to the ``score`` method.\n",
            " |      \n",
            " |      Note that this method is only relevant if\n",
            " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
            " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
            " |      mechanism works.\n",
            " |      \n",
            " |      The options for each parameter are:\n",
            " |      \n",
            " |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
            " |      \n",
            " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
            " |      \n",
            " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
            " |      \n",
            " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
            " |      \n",
            " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
            " |      existing request. This allows you to change the request for some\n",
            " |      parameters and not others.\n",
            " |      \n",
            " |      .. versionadded:: 1.3\n",
            " |      \n",
            " |      .. note::\n",
            " |          This method is only relevant if this estimator is used as a\n",
            " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
            " |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            " |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : object\n",
            " |          The updated object.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes defined here:\n",
            " |  \n",
            " |  __abstractmethods__ = frozenset()\n",
            " |  \n",
            " |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
            " |  \n",
            " |  score(self, X, y, sample_weight=None)\n",
            " |      Return the mean accuracy on the given test data and labels.\n",
            " |      \n",
            " |      In multi-label classification, this is the subset accuracy\n",
            " |      which is a harsh metric since you require for each sample that\n",
            " |      each label set be correctly predicted.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like of shape (n_samples, n_features)\n",
            " |          Test samples.\n",
            " |      \n",
            " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
            " |          True labels for `X`.\n",
            " |      \n",
            " |      sample_weight : array-like of shape (n_samples,), default=None\n",
            " |          Sample weights.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      score : float\n",
            " |          Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from BaseDecisionTree:\n",
            " |  \n",
            " |  apply(self, X, check_input=True)\n",
            " |      Return the index of the leaf that each sample is predicted as.\n",
            " |      \n",
            " |      .. versionadded:: 0.17\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
            " |          The input samples. Internally, it will be converted to\n",
            " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
            " |          to a sparse ``csr_matrix``.\n",
            " |      \n",
            " |      check_input : bool, default=True\n",
            " |          Allow to bypass several input checking.\n",
            " |          Don't use this parameter unless you know what you're doing.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      X_leaves : array-like of shape (n_samples,)\n",
            " |          For each datapoint x in X, return the index of the leaf x\n",
            " |          ends up in. Leaves are numbered within\n",
            " |          ``[0; self.tree_.node_count)``, possibly with gaps in the\n",
            " |          numbering.\n",
            " |  \n",
            " |  cost_complexity_pruning_path(self, X, y, sample_weight=None)\n",
            " |      Compute the pruning path during Minimal Cost-Complexity Pruning.\n",
            " |      \n",
            " |      See :ref:`minimal_cost_complexity_pruning` for details on the pruning\n",
            " |      process.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
            " |          The training input samples. Internally, it will be converted to\n",
            " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
            " |          to a sparse ``csc_matrix``.\n",
            " |      \n",
            " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
            " |          The target values (class labels) as integers or strings.\n",
            " |      \n",
            " |      sample_weight : array-like of shape (n_samples,), default=None\n",
            " |          Sample weights. If None, then samples are equally weighted. Splits\n",
            " |          that would create child nodes with net zero or negative weight are\n",
            " |          ignored while searching for a split in each node. Splits are also\n",
            " |          ignored if they would result in any single class carrying a\n",
            " |          negative weight in either child node.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      ccp_path : :class:`~sklearn.utils.Bunch`\n",
            " |          Dictionary-like object, with the following attributes.\n",
            " |      \n",
            " |          ccp_alphas : ndarray\n",
            " |              Effective alphas of subtree during pruning.\n",
            " |      \n",
            " |          impurities : ndarray\n",
            " |              Sum of the impurities of the subtree leaves for the\n",
            " |              corresponding alpha value in ``ccp_alphas``.\n",
            " |  \n",
            " |  decision_path(self, X, check_input=True)\n",
            " |      Return the decision path in the tree.\n",
            " |      \n",
            " |      .. versionadded:: 0.18\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
            " |          The input samples. Internally, it will be converted to\n",
            " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
            " |          to a sparse ``csr_matrix``.\n",
            " |      \n",
            " |      check_input : bool, default=True\n",
            " |          Allow to bypass several input checking.\n",
            " |          Don't use this parameter unless you know what you're doing.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      indicator : sparse matrix of shape (n_samples, n_nodes)\n",
            " |          Return a node indicator CSR matrix where non zero elements\n",
            " |          indicates that the samples goes through the nodes.\n",
            " |  \n",
            " |  get_depth(self)\n",
            " |      Return the depth of the decision tree.\n",
            " |      \n",
            " |      The depth of a tree is the maximum distance between the root\n",
            " |      and any leaf.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self.tree_.max_depth : int\n",
            " |          The maximum depth of the tree.\n",
            " |  \n",
            " |  get_n_leaves(self)\n",
            " |      Return the number of leaves of the decision tree.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self.tree_.n_leaves : int\n",
            " |          Number of leaves.\n",
            " |  \n",
            " |  predict(self, X, check_input=True)\n",
            " |      Predict class or regression value for X.\n",
            " |      \n",
            " |      For a classification model, the predicted class for each sample in X is\n",
            " |      returned. For a regression model, the predicted value based on X is\n",
            " |      returned.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
            " |          The input samples. Internally, it will be converted to\n",
            " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
            " |          to a sparse ``csr_matrix``.\n",
            " |      \n",
            " |      check_input : bool, default=True\n",
            " |          Allow to bypass several input checking.\n",
            " |          Don't use this parameter unless you know what you're doing.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
            " |          The predicted classes, or the predict values.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Readonly properties inherited from BaseDecisionTree:\n",
            " |  \n",
            " |  feature_importances_\n",
            " |      Return the feature importances.\n",
            " |      \n",
            " |      The importance of a feature is computed as the (normalized) total\n",
            " |      reduction of the criterion brought by that feature.\n",
            " |      It is also known as the Gini importance.\n",
            " |      \n",
            " |      Warning: impurity-based feature importances can be misleading for\n",
            " |      high cardinality features (many unique values). See\n",
            " |      :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      feature_importances_ : ndarray of shape (n_features,)\n",
            " |          Normalized total reduction of criteria by feature\n",
            " |          (Gini importance).\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.base.BaseEstimator:\n",
            " |  \n",
            " |  __getstate__(self)\n",
            " |      Helper for pickle.\n",
            " |  \n",
            " |  __repr__(self, N_CHAR_MAX=700)\n",
            " |      Return repr(self).\n",
            " |  \n",
            " |  __setstate__(self, state)\n",
            " |  \n",
            " |  __sklearn_clone__(self)\n",
            " |  \n",
            " |  get_params(self, deep=True)\n",
            " |      Get parameters for this estimator.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      deep : bool, default=True\n",
            " |          If True, will return the parameters for this estimator and\n",
            " |          contained subobjects that are estimators.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      params : dict\n",
            " |          Parameter names mapped to their values.\n",
            " |  \n",
            " |  set_params(self, **params)\n",
            " |      Set the parameters of this estimator.\n",
            " |      \n",
            " |      The method works on simple estimators as well as on nested objects\n",
            " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
            " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
            " |      possible to update each component of a nested object.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      **params : dict\n",
            " |          Estimator parameters.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : estimator instance\n",
            " |          Estimator instance.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
            " |  \n",
            " |  get_metadata_routing(self)\n",
            " |      Get metadata routing of this object.\n",
            " |      \n",
            " |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
            " |      mechanism works.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      routing : MetadataRequest\n",
            " |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
            " |          routing information.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
            " |  \n",
            " |  __init_subclass__(**kwargs) from abc.ABCMeta\n",
            " |      Set the ``set_{method}_request`` methods.\n",
            " |      \n",
            " |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
            " |      looks for the information available in the set default values which are\n",
            " |      set using ``__metadata_request__*`` class attributes, or inferred\n",
            " |      from method signatures.\n",
            " |      \n",
            " |      The ``__metadata_request__*`` class attributes are used when a method\n",
            " |      does not explicitly accept a metadata through its arguments or if the\n",
            " |      developer would like to specify a request value for those metadata\n",
            " |      which are different from the default ``None``.\n",
            " |      \n",
            " |      References\n",
            " |      ----------\n",
            " |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(DecisionTreeClassifier)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yofVx0DZK9Fr"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "QBhtLDjOJlYK",
        "outputId": "be4b45bf-af59-4f14-88f4-7bd2cb0dec22"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "DecisionTreeClassifier()"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(X_train,Y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BB4Pl19ELAad"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "prrFMOUNKFE8"
      },
      "outputs": [],
      "source": [
        "X_test_pred = dt.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "7GhWVHk0LDdM"
      },
      "outputs": [],
      "source": [
        "X_train_pred = dt.predict(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pK2sbIoeKyNQ"
      },
      "source": [
        "# Testing Data Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chsOtBvqKTg0",
        "outputId": "797ad754-e279-4028-fee5-f5c2e924b9c8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "95.83333333333334"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.mean(Y_test == X_test_pred) *100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNdkDbO3Kch8",
        "outputId": "5f447957-5a86-4b4a-f53e-23fc40db3572"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "95.83333333333334"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dt_test_acc = accuracy_score(Y_test,X_test_pred)\n",
        "dt_test_acc*100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4viMO-fK1TS"
      },
      "source": [
        "# Training Data Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-0POi-zK5_8",
        "outputId": "77f9c609-f1f0-4acf-9d77-a80231ec6c3d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "100.0"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.mean(Y_train == X_train_pred) *100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wVih6pzLP8M",
        "outputId": "a1d41872-86d8-40d5-f2d9-e293d0bda210"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "100.0"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dt_train_acc = accuracy_score(Y_train,X_train_pred)\n",
        "dt_train_acc*100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xN4A5LdaLw8n"
      },
      "source": [
        "# Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGP-d6X4L0Fe",
        "outputId": "ec97e87b-1272-45e0-89d8-074500c66dfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.96      0.96        70\n",
            "           1       0.94      0.96      0.95        50\n",
            "\n",
            "    accuracy                           0.96       120\n",
            "   macro avg       0.96      0.96      0.96       120\n",
            "weighted avg       0.96      0.96      0.96       120\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(Y_test,X_test_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHebq0FxM5A_"
      },
      "source": [
        "# Model with Entropy criterion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "Ot3JtWdrM-pf",
        "outputId": "c3cf0474-6376-499d-b38a-a16302d44095"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "DecisionTreeClassifier(criterion='entropy')"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dt = DecisionTreeClassifier(criterion='entropy')\n",
        "dt.fit(X_train,Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "4200iK1mNNb1"
      },
      "outputs": [],
      "source": [
        "X_train_pred = dt.predict(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "OhA75AqJNOju"
      },
      "outputs": [],
      "source": [
        "X_test_pred = dt.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrQ5Qa3mNUSv"
      },
      "source": [
        "# Test Data Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGIo7ZhVNXcu",
        "outputId": "c101bbb7-c17e-4c43-aeb2-1814436fe985"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "99.16666666666667"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.mean(Y_test == X_test_pred) *100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3K4RC70NZla",
        "outputId": "694962e7-ca84-4a6e-eae6-a1a87e71bcb6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "99.16666666666667"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dt_test_acc = accuracy_score(Y_test,X_test_pred)\n",
        "dt_test_acc*100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiAS9iOnNfht"
      },
      "source": [
        "# Train Data Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UDqP1B5Nh_4",
        "outputId": "7bb54af1-107f-4f40-ec85-9295635001aa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "100.0"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.mean(Y_train == X_train_pred) *100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiH7UF_JNqv_",
        "outputId": "9c4f7a22-c9da-43ef-e6f4-d2f5a466db53"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "100.0"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dt_train_acc = accuracy_score(Y_train,X_train_pred)\n",
        "dt_train_acc*100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89EiownnNyPX"
      },
      "source": [
        "# Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnGvWUa0N1A3",
        "outputId": "bc635423-02fd-4254-9231-77ecde79aeeb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99        70\n",
            "           1       0.98      1.00      0.99        50\n",
            "\n",
            "    accuracy                           0.99       120\n",
            "   macro avg       0.99      0.99      0.99       120\n",
            "weighted avg       0.99      0.99      0.99       120\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(Y_test,X_test_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyvnFSJKRG9K"
      },
      "source": [
        "# Hyper Parameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "wUhyC1nROMT7"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "#dir(model_selection)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwtTtQXfOBZq",
        "outputId": "0a70b548-801a-468d-9cf0-8fca004144b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on class GridSearchCV in module sklearn.model_selection._search:\n",
            "\n",
            "class GridSearchCV(BaseSearchCV)\n",
            " |  GridSearchCV(estimator, param_grid, *, scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
            " |  \n",
            " |  Exhaustive search over specified parameter values for an estimator.\n",
            " |  \n",
            " |  Important members are fit, predict.\n",
            " |  \n",
            " |  GridSearchCV implements a \"fit\" and a \"score\" method.\n",
            " |  It also implements \"score_samples\", \"predict\", \"predict_proba\",\n",
            " |  \"decision_function\", \"transform\" and \"inverse_transform\" if they are\n",
            " |  implemented in the estimator used.\n",
            " |  \n",
            " |  The parameters of the estimator used to apply these methods are optimized\n",
            " |  by cross-validated grid-search over a parameter grid.\n",
            " |  \n",
            " |  Read more in the :ref:`User Guide <grid_search>`.\n",
            " |  \n",
            " |  Parameters\n",
            " |  ----------\n",
            " |  estimator : estimator object\n",
            " |      This is assumed to implement the scikit-learn estimator interface.\n",
            " |      Either estimator needs to provide a ``score`` function,\n",
            " |      or ``scoring`` must be passed.\n",
            " |  \n",
            " |  param_grid : dict or list of dictionaries\n",
            " |      Dictionary with parameters names (`str`) as keys and lists of\n",
            " |      parameter settings to try as values, or a list of such\n",
            " |      dictionaries, in which case the grids spanned by each dictionary\n",
            " |      in the list are explored. This enables searching over any sequence\n",
            " |      of parameter settings.\n",
            " |  \n",
            " |  scoring : str, callable, list, tuple or dict, default=None\n",
            " |      Strategy to evaluate the performance of the cross-validated model on\n",
            " |      the test set.\n",
            " |  \n",
            " |      If `scoring` represents a single score, one can use:\n",
            " |  \n",
            " |      - a single string (see :ref:`scoring_parameter`);\n",
            " |      - a callable (see :ref:`scoring`) that returns a single value.\n",
            " |  \n",
            " |      If `scoring` represents multiple scores, one can use:\n",
            " |  \n",
            " |      - a list or tuple of unique strings;\n",
            " |      - a callable returning a dictionary where the keys are the metric\n",
            " |        names and the values are the metric scores;\n",
            " |      - a dictionary with metric names as keys and callables a values.\n",
            " |  \n",
            " |      See :ref:`multimetric_grid_search` for an example.\n",
            " |  \n",
            " |  n_jobs : int, default=None\n",
            " |      Number of jobs to run in parallel.\n",
            " |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
            " |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
            " |      for more details.\n",
            " |  \n",
            " |      .. versionchanged:: v0.20\n",
            " |         `n_jobs` default changed from 1 to None\n",
            " |  \n",
            " |  refit : bool, str, or callable, default=True\n",
            " |      Refit an estimator using the best found parameters on the whole\n",
            " |      dataset.\n",
            " |  \n",
            " |      For multiple metric evaluation, this needs to be a `str` denoting the\n",
            " |      scorer that would be used to find the best parameters for refitting\n",
            " |      the estimator at the end.\n",
            " |  \n",
            " |      Where there are considerations other than maximum score in\n",
            " |      choosing a best estimator, ``refit`` can be set to a function which\n",
            " |      returns the selected ``best_index_`` given ``cv_results_``. In that\n",
            " |      case, the ``best_estimator_`` and ``best_params_`` will be set\n",
            " |      according to the returned ``best_index_`` while the ``best_score_``\n",
            " |      attribute will not be available.\n",
            " |  \n",
            " |      The refitted estimator is made available at the ``best_estimator_``\n",
            " |      attribute and permits using ``predict`` directly on this\n",
            " |      ``GridSearchCV`` instance.\n",
            " |  \n",
            " |      Also for multiple metric evaluation, the attributes ``best_index_``,\n",
            " |      ``best_score_`` and ``best_params_`` will only be available if\n",
            " |      ``refit`` is set and all of them will be determined w.r.t this specific\n",
            " |      scorer.\n",
            " |  \n",
            " |      See ``scoring`` parameter to know more about multiple metric\n",
            " |      evaluation.\n",
            " |  \n",
            " |      See :ref:`sphx_glr_auto_examples_model_selection_plot_grid_search_digits.py`\n",
            " |      to see how to design a custom selection strategy using a callable\n",
            " |      via `refit`.\n",
            " |  \n",
            " |      .. versionchanged:: 0.20\n",
            " |          Support for callable added.\n",
            " |  \n",
            " |  cv : int, cross-validation generator or an iterable, default=None\n",
            " |      Determines the cross-validation splitting strategy.\n",
            " |      Possible inputs for cv are:\n",
            " |  \n",
            " |      - None, to use the default 5-fold cross validation,\n",
            " |      - integer, to specify the number of folds in a `(Stratified)KFold`,\n",
            " |      - :term:`CV splitter`,\n",
            " |      - An iterable yielding (train, test) splits as arrays of indices.\n",
            " |  \n",
            " |      For integer/None inputs, if the estimator is a classifier and ``y`` is\n",
            " |      either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
            " |      other cases, :class:`KFold` is used. These splitters are instantiated\n",
            " |      with `shuffle=False` so the splits will be the same across calls.\n",
            " |  \n",
            " |      Refer :ref:`User Guide <cross_validation>` for the various\n",
            " |      cross-validation strategies that can be used here.\n",
            " |  \n",
            " |      .. versionchanged:: 0.22\n",
            " |          ``cv`` default value if None changed from 3-fold to 5-fold.\n",
            " |  \n",
            " |  verbose : int\n",
            " |      Controls the verbosity: the higher, the more messages.\n",
            " |  \n",
            " |      - >1 : the computation time for each fold and parameter candidate is\n",
            " |        displayed;\n",
            " |      - >2 : the score is also displayed;\n",
            " |      - >3 : the fold and candidate parameter indexes are also displayed\n",
            " |        together with the starting time of the computation.\n",
            " |  \n",
            " |  pre_dispatch : int, or str, default='2*n_jobs'\n",
            " |      Controls the number of jobs that get dispatched during parallel\n",
            " |      execution. Reducing this number can be useful to avoid an\n",
            " |      explosion of memory consumption when more jobs get dispatched\n",
            " |      than CPUs can process. This parameter can be:\n",
            " |  \n",
            " |          - None, in which case all the jobs are immediately\n",
            " |            created and spawned. Use this for lightweight and\n",
            " |            fast-running jobs, to avoid delays due to on-demand\n",
            " |            spawning of the jobs\n",
            " |  \n",
            " |          - An int, giving the exact number of total jobs that are\n",
            " |            spawned\n",
            " |  \n",
            " |          - A str, giving an expression as a function of n_jobs,\n",
            " |            as in '2*n_jobs'\n",
            " |  \n",
            " |  error_score : 'raise' or numeric, default=np.nan\n",
            " |      Value to assign to the score if an error occurs in estimator fitting.\n",
            " |      If set to 'raise', the error is raised. If a numeric value is given,\n",
            " |      FitFailedWarning is raised. This parameter does not affect the refit\n",
            " |      step, which will always raise the error.\n",
            " |  \n",
            " |  return_train_score : bool, default=False\n",
            " |      If ``False``, the ``cv_results_`` attribute will not include training\n",
            " |      scores.\n",
            " |      Computing training scores is used to get insights on how different\n",
            " |      parameter settings impact the overfitting/underfitting trade-off.\n",
            " |      However computing the scores on the training set can be computationally\n",
            " |      expensive and is not strictly required to select the parameters that\n",
            " |      yield the best generalization performance.\n",
            " |  \n",
            " |      .. versionadded:: 0.19\n",
            " |  \n",
            " |      .. versionchanged:: 0.21\n",
            " |          Default value was changed from ``True`` to ``False``\n",
            " |  \n",
            " |  Attributes\n",
            " |  ----------\n",
            " |  cv_results_ : dict of numpy (masked) ndarrays\n",
            " |      A dict with keys as column headers and values as columns, that can be\n",
            " |      imported into a pandas ``DataFrame``.\n",
            " |  \n",
            " |      For instance the below given table\n",
            " |  \n",
            " |      +------------+-----------+------------+-----------------+---+---------+\n",
            " |      |param_kernel|param_gamma|param_degree|split0_test_score|...|rank_t...|\n",
            " |      +============+===========+============+=================+===+=========+\n",
            " |      |  'poly'    |     --    |      2     |       0.80      |...|    2    |\n",
            " |      +------------+-----------+------------+-----------------+---+---------+\n",
            " |      |  'poly'    |     --    |      3     |       0.70      |...|    4    |\n",
            " |      +------------+-----------+------------+-----------------+---+---------+\n",
            " |      |  'rbf'     |     0.1   |     --     |       0.80      |...|    3    |\n",
            " |      +------------+-----------+------------+-----------------+---+---------+\n",
            " |      |  'rbf'     |     0.2   |     --     |       0.93      |...|    1    |\n",
            " |      +------------+-----------+------------+-----------------+---+---------+\n",
            " |  \n",
            " |      will be represented by a ``cv_results_`` dict of::\n",
            " |  \n",
            " |          {\n",
            " |          'param_kernel': masked_array(data = ['poly', 'poly', 'rbf', 'rbf'],\n",
            " |                                       mask = [False False False False]...)\n",
            " |          'param_gamma': masked_array(data = [-- -- 0.1 0.2],\n",
            " |                                      mask = [ True  True False False]...),\n",
            " |          'param_degree': masked_array(data = [2.0 3.0 -- --],\n",
            " |                                       mask = [False False  True  True]...),\n",
            " |          'split0_test_score'  : [0.80, 0.70, 0.80, 0.93],\n",
            " |          'split1_test_score'  : [0.82, 0.50, 0.70, 0.78],\n",
            " |          'mean_test_score'    : [0.81, 0.60, 0.75, 0.85],\n",
            " |          'std_test_score'     : [0.01, 0.10, 0.05, 0.08],\n",
            " |          'rank_test_score'    : [2, 4, 3, 1],\n",
            " |          'split0_train_score' : [0.80, 0.92, 0.70, 0.93],\n",
            " |          'split1_train_score' : [0.82, 0.55, 0.70, 0.87],\n",
            " |          'mean_train_score'   : [0.81, 0.74, 0.70, 0.90],\n",
            " |          'std_train_score'    : [0.01, 0.19, 0.00, 0.03],\n",
            " |          'mean_fit_time'      : [0.73, 0.63, 0.43, 0.49],\n",
            " |          'std_fit_time'       : [0.01, 0.02, 0.01, 0.01],\n",
            " |          'mean_score_time'    : [0.01, 0.06, 0.04, 0.04],\n",
            " |          'std_score_time'     : [0.00, 0.00, 0.00, 0.01],\n",
            " |          'params'             : [{'kernel': 'poly', 'degree': 2}, ...],\n",
            " |          }\n",
            " |  \n",
            " |      NOTE\n",
            " |  \n",
            " |      The key ``'params'`` is used to store a list of parameter\n",
            " |      settings dicts for all the parameter candidates.\n",
            " |  \n",
            " |      The ``mean_fit_time``, ``std_fit_time``, ``mean_score_time`` and\n",
            " |      ``std_score_time`` are all in seconds.\n",
            " |  \n",
            " |      For multi-metric evaluation, the scores for all the scorers are\n",
            " |      available in the ``cv_results_`` dict at the keys ending with that\n",
            " |      scorer's name (``'_<scorer_name>'``) instead of ``'_score'`` shown\n",
            " |      above. ('split0_test_precision', 'mean_train_precision' etc.)\n",
            " |  \n",
            " |  best_estimator_ : estimator\n",
            " |      Estimator that was chosen by the search, i.e. estimator\n",
            " |      which gave highest score (or smallest loss if specified)\n",
            " |      on the left out data. Not available if ``refit=False``.\n",
            " |  \n",
            " |      See ``refit`` parameter for more information on allowed values.\n",
            " |  \n",
            " |  best_score_ : float\n",
            " |      Mean cross-validated score of the best_estimator\n",
            " |  \n",
            " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
            " |      specified.\n",
            " |  \n",
            " |      This attribute is not available if ``refit`` is a function.\n",
            " |  \n",
            " |  best_params_ : dict\n",
            " |      Parameter setting that gave the best results on the hold out data.\n",
            " |  \n",
            " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
            " |      specified.\n",
            " |  \n",
            " |  best_index_ : int\n",
            " |      The index (of the ``cv_results_`` arrays) which corresponds to the best\n",
            " |      candidate parameter setting.\n",
            " |  \n",
            " |      The dict at ``search.cv_results_['params'][search.best_index_]`` gives\n",
            " |      the parameter setting for the best model, that gives the highest\n",
            " |      mean score (``search.best_score_``).\n",
            " |  \n",
            " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
            " |      specified.\n",
            " |  \n",
            " |  scorer_ : function or a dict\n",
            " |      Scorer function used on the held out data to choose the best\n",
            " |      parameters for the model.\n",
            " |  \n",
            " |      For multi-metric evaluation, this attribute holds the validated\n",
            " |      ``scoring`` dict which maps the scorer key to the scorer callable.\n",
            " |  \n",
            " |  n_splits_ : int\n",
            " |      The number of cross-validation splits (folds/iterations).\n",
            " |  \n",
            " |  refit_time_ : float\n",
            " |      Seconds used for refitting the best model on the whole dataset.\n",
            " |  \n",
            " |      This is present only if ``refit`` is not False.\n",
            " |  \n",
            " |      .. versionadded:: 0.20\n",
            " |  \n",
            " |  multimetric_ : bool\n",
            " |      Whether or not the scorers compute several metrics.\n",
            " |  \n",
            " |  classes_ : ndarray of shape (n_classes,)\n",
            " |      The classes labels. This is present only if ``refit`` is specified and\n",
            " |      the underlying estimator is a classifier.\n",
            " |  \n",
            " |  n_features_in_ : int\n",
            " |      Number of features seen during :term:`fit`. Only defined if\n",
            " |      `best_estimator_` is defined (see the documentation for the `refit`\n",
            " |      parameter for more details) and that `best_estimator_` exposes\n",
            " |      `n_features_in_` when fit.\n",
            " |  \n",
            " |      .. versionadded:: 0.24\n",
            " |  \n",
            " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
            " |      Names of features seen during :term:`fit`. Only defined if\n",
            " |      `best_estimator_` is defined (see the documentation for the `refit`\n",
            " |      parameter for more details) and that `best_estimator_` exposes\n",
            " |      `feature_names_in_` when fit.\n",
            " |  \n",
            " |      .. versionadded:: 1.0\n",
            " |  \n",
            " |  See Also\n",
            " |  --------\n",
            " |  ParameterGrid : Generates all the combinations of a hyperparameter grid.\n",
            " |  train_test_split : Utility function to split the data into a development\n",
            " |      set usable for fitting a GridSearchCV instance and an evaluation set\n",
            " |      for its final evaluation.\n",
            " |  sklearn.metrics.make_scorer : Make a scorer from a performance metric or\n",
            " |      loss function.\n",
            " |  \n",
            " |  Notes\n",
            " |  -----\n",
            " |  The parameters selected are those that maximize the score of the left out\n",
            " |  data, unless an explicit score is passed in which case it is used instead.\n",
            " |  \n",
            " |  If `n_jobs` was set to a value higher than one, the data is copied for each\n",
            " |  point in the grid (and not `n_jobs` times). This is done for efficiency\n",
            " |  reasons if individual jobs take very little time, but may raise errors if\n",
            " |  the dataset is large and not enough memory is available.  A workaround in\n",
            " |  this case is to set `pre_dispatch`. Then, the memory is copied only\n",
            " |  `pre_dispatch` many times. A reasonable value for `pre_dispatch` is `2 *\n",
            " |  n_jobs`.\n",
            " |  \n",
            " |  Examples\n",
            " |  --------\n",
            " |  >>> from sklearn import svm, datasets\n",
            " |  >>> from sklearn.model_selection import GridSearchCV\n",
            " |  >>> iris = datasets.load_iris()\n",
            " |  >>> parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
            " |  >>> svc = svm.SVC()\n",
            " |  >>> clf = GridSearchCV(svc, parameters)\n",
            " |  >>> clf.fit(iris.data, iris.target)\n",
            " |  GridSearchCV(estimator=SVC(),\n",
            " |               param_grid={'C': [1, 10], 'kernel': ('linear', 'rbf')})\n",
            " |  >>> sorted(clf.cv_results_.keys())\n",
            " |  ['mean_fit_time', 'mean_score_time', 'mean_test_score',...\n",
            " |   'param_C', 'param_kernel', 'params',...\n",
            " |   'rank_test_score', 'split0_test_score',...\n",
            " |   'split2_test_score', ...\n",
            " |   'std_fit_time', 'std_score_time', 'std_test_score']\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      GridSearchCV\n",
            " |      BaseSearchCV\n",
            " |      sklearn.base.MetaEstimatorMixin\n",
            " |      sklearn.base.BaseEstimator\n",
            " |      sklearn.utils._metadata_requests._MetadataRequester\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, estimator, param_grid, *, scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
            " |      Initialize self.  See help(type(self)) for accurate signature.\n",
            " |  \n",
            " |  set_fit_request(self: sklearn.model_selection._search.GridSearchCV, *, groups: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.model_selection._search.GridSearchCV\n",
            " |      Request metadata passed to the ``fit`` method.\n",
            " |      \n",
            " |      Note that this method is only relevant if\n",
            " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
            " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
            " |      mechanism works.\n",
            " |      \n",
            " |      The options for each parameter are:\n",
            " |      \n",
            " |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
            " |      \n",
            " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
            " |      \n",
            " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
            " |      \n",
            " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
            " |      \n",
            " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
            " |      existing request. This allows you to change the request for some\n",
            " |      parameters and not others.\n",
            " |      \n",
            " |      .. versionadded:: 1.3\n",
            " |      \n",
            " |      .. note::\n",
            " |          This method is only relevant if this estimator is used as a\n",
            " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
            " |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      groups : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            " |          Metadata routing for ``groups`` parameter in ``fit``.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : object\n",
            " |          The updated object.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes defined here:\n",
            " |  \n",
            " |  __abstractmethods__ = frozenset()\n",
            " |  \n",
            " |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from BaseSearchCV:\n",
            " |  \n",
            " |  decision_function(self, X)\n",
            " |      Call decision_function on the estimator with the best found parameters.\n",
            " |      \n",
            " |      Only available if ``refit=True`` and the underlying estimator supports\n",
            " |      ``decision_function``.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : indexable, length n_samples\n",
            " |          Must fulfill the input assumptions of the\n",
            " |          underlying estimator.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      y_score : ndarray of shape (n_samples,) or (n_samples, n_classes)                 or (n_samples, n_classes * (n_classes-1) / 2)\n",
            " |          Result of the decision function for `X` based on the estimator with\n",
            " |          the best found parameters.\n",
            " |  \n",
            " |  fit(self, X, y=None, *, groups=None, **fit_params)\n",
            " |      Run fit with all sets of parameters.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      \n",
            " |      X : array-like of shape (n_samples, n_features)\n",
            " |          Training vector, where `n_samples` is the number of samples and\n",
            " |          `n_features` is the number of features.\n",
            " |      \n",
            " |      y : array-like of shape (n_samples, n_output)             or (n_samples,), default=None\n",
            " |          Target relative to X for classification or regression;\n",
            " |          None for unsupervised learning.\n",
            " |      \n",
            " |      groups : array-like of shape (n_samples,), default=None\n",
            " |          Group labels for the samples used while splitting the dataset into\n",
            " |          train/test set. Only used in conjunction with a \"Group\" :term:`cv`\n",
            " |          instance (e.g., :class:`~sklearn.model_selection.GroupKFold`).\n",
            " |      \n",
            " |      **fit_params : dict of str -> object\n",
            " |          Parameters passed to the `fit` method of the estimator.\n",
            " |      \n",
            " |          If a fit parameter is an array-like whose length is equal to\n",
            " |          `num_samples` then it will be split across CV groups along with `X`\n",
            " |          and `y`. For example, the :term:`sample_weight` parameter is split\n",
            " |          because `len(sample_weights) = len(X)`.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : object\n",
            " |          Instance of fitted estimator.\n",
            " |  \n",
            " |  inverse_transform(self, Xt)\n",
            " |      Call inverse_transform on the estimator with the best found params.\n",
            " |      \n",
            " |      Only available if the underlying estimator implements\n",
            " |      ``inverse_transform`` and ``refit=True``.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      Xt : indexable, length n_samples\n",
            " |          Must fulfill the input assumptions of the\n",
            " |          underlying estimator.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      X : {ndarray, sparse matrix} of shape (n_samples, n_features)\n",
            " |          Result of the `inverse_transform` function for `Xt` based on the\n",
            " |          estimator with the best found parameters.\n",
            " |  \n",
            " |  predict(self, X)\n",
            " |      Call predict on the estimator with the best found parameters.\n",
            " |      \n",
            " |      Only available if ``refit=True`` and the underlying estimator supports\n",
            " |      ``predict``.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : indexable, length n_samples\n",
            " |          Must fulfill the input assumptions of the\n",
            " |          underlying estimator.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      y_pred : ndarray of shape (n_samples,)\n",
            " |          The predicted labels or values for `X` based on the estimator with\n",
            " |          the best found parameters.\n",
            " |  \n",
            " |  predict_log_proba(self, X)\n",
            " |      Call predict_log_proba on the estimator with the best found parameters.\n",
            " |      \n",
            " |      Only available if ``refit=True`` and the underlying estimator supports\n",
            " |      ``predict_log_proba``.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : indexable, length n_samples\n",
            " |          Must fulfill the input assumptions of the\n",
            " |          underlying estimator.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      y_pred : ndarray of shape (n_samples,) or (n_samples, n_classes)\n",
            " |          Predicted class log-probabilities for `X` based on the estimator\n",
            " |          with the best found parameters. The order of the classes\n",
            " |          corresponds to that in the fitted attribute :term:`classes_`.\n",
            " |  \n",
            " |  predict_proba(self, X)\n",
            " |      Call predict_proba on the estimator with the best found parameters.\n",
            " |      \n",
            " |      Only available if ``refit=True`` and the underlying estimator supports\n",
            " |      ``predict_proba``.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : indexable, length n_samples\n",
            " |          Must fulfill the input assumptions of the\n",
            " |          underlying estimator.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      y_pred : ndarray of shape (n_samples,) or (n_samples, n_classes)\n",
            " |          Predicted class probabilities for `X` based on the estimator with\n",
            " |          the best found parameters. The order of the classes corresponds\n",
            " |          to that in the fitted attribute :term:`classes_`.\n",
            " |  \n",
            " |  score(self, X, y=None)\n",
            " |      Return the score on the given data, if the estimator has been refit.\n",
            " |      \n",
            " |      This uses the score defined by ``scoring`` where provided, and the\n",
            " |      ``best_estimator_.score`` method otherwise.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like of shape (n_samples, n_features)\n",
            " |          Input data, where `n_samples` is the number of samples and\n",
            " |          `n_features` is the number of features.\n",
            " |      \n",
            " |      y : array-like of shape (n_samples, n_output)             or (n_samples,), default=None\n",
            " |          Target relative to X for classification or regression;\n",
            " |          None for unsupervised learning.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      score : float\n",
            " |          The score defined by ``scoring`` if provided, and the\n",
            " |          ``best_estimator_.score`` method otherwise.\n",
            " |  \n",
            " |  score_samples(self, X)\n",
            " |      Call score_samples on the estimator with the best found parameters.\n",
            " |      \n",
            " |      Only available if ``refit=True`` and the underlying estimator supports\n",
            " |      ``score_samples``.\n",
            " |      \n",
            " |      .. versionadded:: 0.24\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : iterable\n",
            " |          Data to predict on. Must fulfill input requirements\n",
            " |          of the underlying estimator.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      y_score : ndarray of shape (n_samples,)\n",
            " |          The ``best_estimator_.score_samples`` method.\n",
            " |  \n",
            " |  transform(self, X)\n",
            " |      Call transform on the estimator with the best found parameters.\n",
            " |      \n",
            " |      Only available if the underlying estimator supports ``transform`` and\n",
            " |      ``refit=True``.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : indexable, length n_samples\n",
            " |          Must fulfill the input assumptions of the\n",
            " |          underlying estimator.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      Xt : {ndarray, sparse matrix} of shape (n_samples, n_features)\n",
            " |          `X` transformed in the new space based on the estimator with\n",
            " |          the best found parameters.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Readonly properties inherited from BaseSearchCV:\n",
            " |  \n",
            " |  classes_\n",
            " |      Class labels.\n",
            " |      \n",
            " |      Only available when `refit=True` and the estimator is a classifier.\n",
            " |  \n",
            " |  n_features_in_\n",
            " |      Number of features seen during :term:`fit`.\n",
            " |      \n",
            " |      Only available when `refit=True`.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from sklearn.base.MetaEstimatorMixin:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.base.BaseEstimator:\n",
            " |  \n",
            " |  __getstate__(self)\n",
            " |      Helper for pickle.\n",
            " |  \n",
            " |  __repr__(self, N_CHAR_MAX=700)\n",
            " |      Return repr(self).\n",
            " |  \n",
            " |  __setstate__(self, state)\n",
            " |  \n",
            " |  __sklearn_clone__(self)\n",
            " |  \n",
            " |  get_params(self, deep=True)\n",
            " |      Get parameters for this estimator.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      deep : bool, default=True\n",
            " |          If True, will return the parameters for this estimator and\n",
            " |          contained subobjects that are estimators.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      params : dict\n",
            " |          Parameter names mapped to their values.\n",
            " |  \n",
            " |  set_params(self, **params)\n",
            " |      Set the parameters of this estimator.\n",
            " |      \n",
            " |      The method works on simple estimators as well as on nested objects\n",
            " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
            " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
            " |      possible to update each component of a nested object.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      **params : dict\n",
            " |          Estimator parameters.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : estimator instance\n",
            " |          Estimator instance.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
            " |  \n",
            " |  get_metadata_routing(self)\n",
            " |      Get metadata routing of this object.\n",
            " |      \n",
            " |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
            " |      mechanism works.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      routing : MetadataRequest\n",
            " |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
            " |          routing information.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
            " |  \n",
            " |  __init_subclass__(**kwargs) from abc.ABCMeta\n",
            " |      Set the ``set_{method}_request`` methods.\n",
            " |      \n",
            " |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
            " |      looks for the information available in the set default values which are\n",
            " |      set using ``__metadata_request__*`` class attributes, or inferred\n",
            " |      from method signatures.\n",
            " |      \n",
            " |      The ``__metadata_request__*`` class attributes are used when a method\n",
            " |      does not explicitly accept a metadata through its arguments or if the\n",
            " |      developer would like to specify a request value for those metadata\n",
            " |      which are different from the default ``None``.\n",
            " |      \n",
            " |      References\n",
            " |      ----------\n",
            " |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(GridSearchCV)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFGzh6iIRYnG",
        "outputId": "e3dc493e-2b41-4428-c06f-7f913f170254"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on class DecisionTreeClassifier in module sklearn.tree._classes:\n",
            "\n",
            "class DecisionTreeClassifier(sklearn.base.ClassifierMixin, BaseDecisionTree)\n",
            " |  DecisionTreeClassifier(*, criterion='gini', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, class_weight=None, ccp_alpha=0.0)\n",
            " |  \n",
            " |  A decision tree classifier.\n",
            " |  \n",
            " |  Read more in the :ref:`User Guide <tree>`.\n",
            " |  \n",
            " |  Parameters\n",
            " |  ----------\n",
            " |  criterion : {\"gini\", \"entropy\", \"log_loss\"}, default=\"gini\"\n",
            " |      The function to measure the quality of a split. Supported criteria are\n",
            " |      \"gini\" for the Gini impurity and \"log_loss\" and \"entropy\" both for the\n",
            " |      Shannon information gain, see :ref:`tree_mathematical_formulation`.\n",
            " |  \n",
            " |  splitter : {\"best\", \"random\"}, default=\"best\"\n",
            " |      The strategy used to choose the split at each node. Supported\n",
            " |      strategies are \"best\" to choose the best split and \"random\" to choose\n",
            " |      the best random split.\n",
            " |  \n",
            " |  max_depth : int, default=None\n",
            " |      The maximum depth of the tree. If None, then nodes are expanded until\n",
            " |      all leaves are pure or until all leaves contain less than\n",
            " |      min_samples_split samples.\n",
            " |  \n",
            " |  min_samples_split : int or float, default=2\n",
            " |      The minimum number of samples required to split an internal node:\n",
            " |  \n",
            " |      - If int, then consider `min_samples_split` as the minimum number.\n",
            " |      - If float, then `min_samples_split` is a fraction and\n",
            " |        `ceil(min_samples_split * n_samples)` are the minimum\n",
            " |        number of samples for each split.\n",
            " |  \n",
            " |      .. versionchanged:: 0.18\n",
            " |         Added float values for fractions.\n",
            " |  \n",
            " |  min_samples_leaf : int or float, default=1\n",
            " |      The minimum number of samples required to be at a leaf node.\n",
            " |      A split point at any depth will only be considered if it leaves at\n",
            " |      least ``min_samples_leaf`` training samples in each of the left and\n",
            " |      right branches.  This may have the effect of smoothing the model,\n",
            " |      especially in regression.\n",
            " |  \n",
            " |      - If int, then consider `min_samples_leaf` as the minimum number.\n",
            " |      - If float, then `min_samples_leaf` is a fraction and\n",
            " |        `ceil(min_samples_leaf * n_samples)` are the minimum\n",
            " |        number of samples for each node.\n",
            " |  \n",
            " |      .. versionchanged:: 0.18\n",
            " |         Added float values for fractions.\n",
            " |  \n",
            " |  min_weight_fraction_leaf : float, default=0.0\n",
            " |      The minimum weighted fraction of the sum total of weights (of all\n",
            " |      the input samples) required to be at a leaf node. Samples have\n",
            " |      equal weight when sample_weight is not provided.\n",
            " |  \n",
            " |  max_features : int, float or {\"auto\", \"sqrt\", \"log2\"}, default=None\n",
            " |      The number of features to consider when looking for the best split:\n",
            " |  \n",
            " |          - If int, then consider `max_features` features at each split.\n",
            " |          - If float, then `max_features` is a fraction and\n",
            " |            `max(1, int(max_features * n_features_in_))` features are considered at\n",
            " |            each split.\n",
            " |          - If \"sqrt\", then `max_features=sqrt(n_features)`.\n",
            " |          - If \"log2\", then `max_features=log2(n_features)`.\n",
            " |          - If None, then `max_features=n_features`.\n",
            " |  \n",
            " |      Note: the search for a split does not stop until at least one\n",
            " |      valid partition of the node samples is found, even if it requires to\n",
            " |      effectively inspect more than ``max_features`` features.\n",
            " |  \n",
            " |  random_state : int, RandomState instance or None, default=None\n",
            " |      Controls the randomness of the estimator. The features are always\n",
            " |      randomly permuted at each split, even if ``splitter`` is set to\n",
            " |      ``\"best\"``. When ``max_features < n_features``, the algorithm will\n",
            " |      select ``max_features`` at random at each split before finding the best\n",
            " |      split among them. But the best found split may vary across different\n",
            " |      runs, even if ``max_features=n_features``. That is the case, if the\n",
            " |      improvement of the criterion is identical for several splits and one\n",
            " |      split has to be selected at random. To obtain a deterministic behaviour\n",
            " |      during fitting, ``random_state`` has to be fixed to an integer.\n",
            " |      See :term:`Glossary <random_state>` for details.\n",
            " |  \n",
            " |  max_leaf_nodes : int, default=None\n",
            " |      Grow a tree with ``max_leaf_nodes`` in best-first fashion.\n",
            " |      Best nodes are defined as relative reduction in impurity.\n",
            " |      If None then unlimited number of leaf nodes.\n",
            " |  \n",
            " |  min_impurity_decrease : float, default=0.0\n",
            " |      A node will be split if this split induces a decrease of the impurity\n",
            " |      greater than or equal to this value.\n",
            " |  \n",
            " |      The weighted impurity decrease equation is the following::\n",
            " |  \n",
            " |          N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
            " |                              - N_t_L / N_t * left_impurity)\n",
            " |  \n",
            " |      where ``N`` is the total number of samples, ``N_t`` is the number of\n",
            " |      samples at the current node, ``N_t_L`` is the number of samples in the\n",
            " |      left child, and ``N_t_R`` is the number of samples in the right child.\n",
            " |  \n",
            " |      ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
            " |      if ``sample_weight`` is passed.\n",
            " |  \n",
            " |      .. versionadded:: 0.19\n",
            " |  \n",
            " |  class_weight : dict, list of dict or \"balanced\", default=None\n",
            " |      Weights associated with classes in the form ``{class_label: weight}``.\n",
            " |      If None, all classes are supposed to have weight one. For\n",
            " |      multi-output problems, a list of dicts can be provided in the same\n",
            " |      order as the columns of y.\n",
            " |  \n",
            " |      Note that for multioutput (including multilabel) weights should be\n",
            " |      defined for each class of every column in its own dict. For example,\n",
            " |      for four-class multilabel classification weights should be\n",
            " |      [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of\n",
            " |      [{1:1}, {2:5}, {3:1}, {4:1}].\n",
            " |  \n",
            " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
            " |      weights inversely proportional to class frequencies in the input data\n",
            " |      as ``n_samples / (n_classes * np.bincount(y))``\n",
            " |  \n",
            " |      For multi-output, the weights of each column of y will be multiplied.\n",
            " |  \n",
            " |      Note that these weights will be multiplied with sample_weight (passed\n",
            " |      through the fit method) if sample_weight is specified.\n",
            " |  \n",
            " |  ccp_alpha : non-negative float, default=0.0\n",
            " |      Complexity parameter used for Minimal Cost-Complexity Pruning. The\n",
            " |      subtree with the largest cost complexity that is smaller than\n",
            " |      ``ccp_alpha`` will be chosen. By default, no pruning is performed. See\n",
            " |      :ref:`minimal_cost_complexity_pruning` for details.\n",
            " |  \n",
            " |      .. versionadded:: 0.22\n",
            " |  \n",
            " |  Attributes\n",
            " |  ----------\n",
            " |  classes_ : ndarray of shape (n_classes,) or list of ndarray\n",
            " |      The classes labels (single output problem),\n",
            " |      or a list of arrays of class labels (multi-output problem).\n",
            " |  \n",
            " |  feature_importances_ : ndarray of shape (n_features,)\n",
            " |      The impurity-based feature importances.\n",
            " |      The higher, the more important the feature.\n",
            " |      The importance of a feature is computed as the (normalized)\n",
            " |      total reduction of the criterion brought by that feature.  It is also\n",
            " |      known as the Gini importance [4]_.\n",
            " |  \n",
            " |      Warning: impurity-based feature importances can be misleading for\n",
            " |      high cardinality features (many unique values). See\n",
            " |      :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
            " |  \n",
            " |  max_features_ : int\n",
            " |      The inferred value of max_features.\n",
            " |  \n",
            " |  n_classes_ : int or list of int\n",
            " |      The number of classes (for single output problems),\n",
            " |      or a list containing the number of classes for each\n",
            " |      output (for multi-output problems).\n",
            " |  \n",
            " |  n_features_in_ : int\n",
            " |      Number of features seen during :term:`fit`.\n",
            " |  \n",
            " |      .. versionadded:: 0.24\n",
            " |  \n",
            " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
            " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
            " |      has feature names that are all strings.\n",
            " |  \n",
            " |      .. versionadded:: 1.0\n",
            " |  \n",
            " |  n_outputs_ : int\n",
            " |      The number of outputs when ``fit`` is performed.\n",
            " |  \n",
            " |  tree_ : Tree instance\n",
            " |      The underlying Tree object. Please refer to\n",
            " |      ``help(sklearn.tree._tree.Tree)`` for attributes of Tree object and\n",
            " |      :ref:`sphx_glr_auto_examples_tree_plot_unveil_tree_structure.py`\n",
            " |      for basic usage of these attributes.\n",
            " |  \n",
            " |  See Also\n",
            " |  --------\n",
            " |  DecisionTreeRegressor : A decision tree regressor.\n",
            " |  \n",
            " |  Notes\n",
            " |  -----\n",
            " |  The default values for the parameters controlling the size of the trees\n",
            " |  (e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\n",
            " |  unpruned trees which can potentially be very large on some data sets. To\n",
            " |  reduce memory consumption, the complexity and size of the trees should be\n",
            " |  controlled by setting those parameter values.\n",
            " |  \n",
            " |  The :meth:`predict` method operates using the :func:`numpy.argmax`\n",
            " |  function on the outputs of :meth:`predict_proba`. This means that in\n",
            " |  case the highest predicted probabilities are tied, the classifier will\n",
            " |  predict the tied class with the lowest index in :term:`classes_`.\n",
            " |  \n",
            " |  References\n",
            " |  ----------\n",
            " |  \n",
            " |  .. [1] https://en.wikipedia.org/wiki/Decision_tree_learning\n",
            " |  \n",
            " |  .. [2] L. Breiman, J. Friedman, R. Olshen, and C. Stone, \"Classification\n",
            " |         and Regression Trees\", Wadsworth, Belmont, CA, 1984.\n",
            " |  \n",
            " |  .. [3] T. Hastie, R. Tibshirani and J. Friedman. \"Elements of Statistical\n",
            " |         Learning\", Springer, 2009.\n",
            " |  \n",
            " |  .. [4] L. Breiman, and A. Cutler, \"Random Forests\",\n",
            " |         https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm\n",
            " |  \n",
            " |  Examples\n",
            " |  --------\n",
            " |  >>> from sklearn.datasets import load_iris\n",
            " |  >>> from sklearn.model_selection import cross_val_score\n",
            " |  >>> from sklearn.tree import DecisionTreeClassifier\n",
            " |  >>> clf = DecisionTreeClassifier(random_state=0)\n",
            " |  >>> iris = load_iris()\n",
            " |  >>> cross_val_score(clf, iris.data, iris.target, cv=10)\n",
            " |  ...                             # doctest: +SKIP\n",
            " |  ...\n",
            " |  array([ 1.     ,  0.93...,  0.86...,  0.93...,  0.93...,\n",
            " |          0.93...,  0.93...,  1.     ,  0.93...,  1.      ])\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      DecisionTreeClassifier\n",
            " |      sklearn.base.ClassifierMixin\n",
            " |      BaseDecisionTree\n",
            " |      sklearn.base.MultiOutputMixin\n",
            " |      sklearn.base.BaseEstimator\n",
            " |      sklearn.utils._metadata_requests._MetadataRequester\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, *, criterion='gini', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, class_weight=None, ccp_alpha=0.0)\n",
            " |      Initialize self.  See help(type(self)) for accurate signature.\n",
            " |  \n",
            " |  fit(self, X, y, sample_weight=None, check_input=True)\n",
            " |      Build a decision tree classifier from the training set (X, y).\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
            " |          The training input samples. Internally, it will be converted to\n",
            " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
            " |          to a sparse ``csc_matrix``.\n",
            " |      \n",
            " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
            " |          The target values (class labels) as integers or strings.\n",
            " |      \n",
            " |      sample_weight : array-like of shape (n_samples,), default=None\n",
            " |          Sample weights. If None, then samples are equally weighted. Splits\n",
            " |          that would create child nodes with net zero or negative weight are\n",
            " |          ignored while searching for a split in each node. Splits are also\n",
            " |          ignored if they would result in any single class carrying a\n",
            " |          negative weight in either child node.\n",
            " |      \n",
            " |      check_input : bool, default=True\n",
            " |          Allow to bypass several input checking.\n",
            " |          Don't use this parameter unless you know what you're doing.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : DecisionTreeClassifier\n",
            " |          Fitted estimator.\n",
            " |  \n",
            " |  predict_log_proba(self, X)\n",
            " |      Predict class log-probabilities of the input samples X.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
            " |          The input samples. Internally, it will be converted to\n",
            " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
            " |          to a sparse ``csr_matrix``.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      proba : ndarray of shape (n_samples, n_classes) or list of n_outputs             such arrays if n_outputs > 1\n",
            " |          The class log-probabilities of the input samples. The order of the\n",
            " |          classes corresponds to that in the attribute :term:`classes_`.\n",
            " |  \n",
            " |  predict_proba(self, X, check_input=True)\n",
            " |      Predict class probabilities of the input samples X.\n",
            " |      \n",
            " |      The predicted class probability is the fraction of samples of the same\n",
            " |      class in a leaf.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
            " |          The input samples. Internally, it will be converted to\n",
            " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
            " |          to a sparse ``csr_matrix``.\n",
            " |      \n",
            " |      check_input : bool, default=True\n",
            " |          Allow to bypass several input checking.\n",
            " |          Don't use this parameter unless you know what you're doing.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      proba : ndarray of shape (n_samples, n_classes) or list of n_outputs             such arrays if n_outputs > 1\n",
            " |          The class probabilities of the input samples. The order of the\n",
            " |          classes corresponds to that in the attribute :term:`classes_`.\n",
            " |  \n",
            " |  set_fit_request(self: sklearn.tree._classes.DecisionTreeClassifier, *, check_input: Union[bool, NoneType, str] = '$UNCHANGED$', sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.tree._classes.DecisionTreeClassifier\n",
            " |      Request metadata passed to the ``fit`` method.\n",
            " |      \n",
            " |      Note that this method is only relevant if\n",
            " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
            " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
            " |      mechanism works.\n",
            " |      \n",
            " |      The options for each parameter are:\n",
            " |      \n",
            " |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
            " |      \n",
            " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
            " |      \n",
            " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
            " |      \n",
            " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
            " |      \n",
            " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
            " |      existing request. This allows you to change the request for some\n",
            " |      parameters and not others.\n",
            " |      \n",
            " |      .. versionadded:: 1.3\n",
            " |      \n",
            " |      .. note::\n",
            " |          This method is only relevant if this estimator is used as a\n",
            " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
            " |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      check_input : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            " |          Metadata routing for ``check_input`` parameter in ``fit``.\n",
            " |      \n",
            " |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            " |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : object\n",
            " |          The updated object.\n",
            " |  \n",
            " |  set_predict_proba_request(self: sklearn.tree._classes.DecisionTreeClassifier, *, check_input: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.tree._classes.DecisionTreeClassifier\n",
            " |      Request metadata passed to the ``predict_proba`` method.\n",
            " |      \n",
            " |      Note that this method is only relevant if\n",
            " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
            " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
            " |      mechanism works.\n",
            " |      \n",
            " |      The options for each parameter are:\n",
            " |      \n",
            " |      - ``True``: metadata is requested, and passed to ``predict_proba`` if provided. The request is ignored if metadata is not provided.\n",
            " |      \n",
            " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``predict_proba``.\n",
            " |      \n",
            " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
            " |      \n",
            " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
            " |      \n",
            " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
            " |      existing request. This allows you to change the request for some\n",
            " |      parameters and not others.\n",
            " |      \n",
            " |      .. versionadded:: 1.3\n",
            " |      \n",
            " |      .. note::\n",
            " |          This method is only relevant if this estimator is used as a\n",
            " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
            " |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      check_input : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            " |          Metadata routing for ``check_input`` parameter in ``predict_proba``.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : object\n",
            " |          The updated object.\n",
            " |  \n",
            " |  set_predict_request(self: sklearn.tree._classes.DecisionTreeClassifier, *, check_input: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.tree._classes.DecisionTreeClassifier\n",
            " |      Request metadata passed to the ``predict`` method.\n",
            " |      \n",
            " |      Note that this method is only relevant if\n",
            " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
            " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
            " |      mechanism works.\n",
            " |      \n",
            " |      The options for each parameter are:\n",
            " |      \n",
            " |      - ``True``: metadata is requested, and passed to ``predict`` if provided. The request is ignored if metadata is not provided.\n",
            " |      \n",
            " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``predict``.\n",
            " |      \n",
            " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
            " |      \n",
            " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
            " |      \n",
            " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
            " |      existing request. This allows you to change the request for some\n",
            " |      parameters and not others.\n",
            " |      \n",
            " |      .. versionadded:: 1.3\n",
            " |      \n",
            " |      .. note::\n",
            " |          This method is only relevant if this estimator is used as a\n",
            " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
            " |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      check_input : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            " |          Metadata routing for ``check_input`` parameter in ``predict``.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : object\n",
            " |          The updated object.\n",
            " |  \n",
            " |  set_score_request(self: sklearn.tree._classes.DecisionTreeClassifier, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.tree._classes.DecisionTreeClassifier\n",
            " |      Request metadata passed to the ``score`` method.\n",
            " |      \n",
            " |      Note that this method is only relevant if\n",
            " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
            " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
            " |      mechanism works.\n",
            " |      \n",
            " |      The options for each parameter are:\n",
            " |      \n",
            " |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
            " |      \n",
            " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
            " |      \n",
            " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
            " |      \n",
            " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
            " |      \n",
            " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
            " |      existing request. This allows you to change the request for some\n",
            " |      parameters and not others.\n",
            " |      \n",
            " |      .. versionadded:: 1.3\n",
            " |      \n",
            " |      .. note::\n",
            " |          This method is only relevant if this estimator is used as a\n",
            " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
            " |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            " |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : object\n",
            " |          The updated object.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes defined here:\n",
            " |  \n",
            " |  __abstractmethods__ = frozenset()\n",
            " |  \n",
            " |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
            " |  \n",
            " |  score(self, X, y, sample_weight=None)\n",
            " |      Return the mean accuracy on the given test data and labels.\n",
            " |      \n",
            " |      In multi-label classification, this is the subset accuracy\n",
            " |      which is a harsh metric since you require for each sample that\n",
            " |      each label set be correctly predicted.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like of shape (n_samples, n_features)\n",
            " |          Test samples.\n",
            " |      \n",
            " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
            " |          True labels for `X`.\n",
            " |      \n",
            " |      sample_weight : array-like of shape (n_samples,), default=None\n",
            " |          Sample weights.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      score : float\n",
            " |          Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from BaseDecisionTree:\n",
            " |  \n",
            " |  apply(self, X, check_input=True)\n",
            " |      Return the index of the leaf that each sample is predicted as.\n",
            " |      \n",
            " |      .. versionadded:: 0.17\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
            " |          The input samples. Internally, it will be converted to\n",
            " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
            " |          to a sparse ``csr_matrix``.\n",
            " |      \n",
            " |      check_input : bool, default=True\n",
            " |          Allow to bypass several input checking.\n",
            " |          Don't use this parameter unless you know what you're doing.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      X_leaves : array-like of shape (n_samples,)\n",
            " |          For each datapoint x in X, return the index of the leaf x\n",
            " |          ends up in. Leaves are numbered within\n",
            " |          ``[0; self.tree_.node_count)``, possibly with gaps in the\n",
            " |          numbering.\n",
            " |  \n",
            " |  cost_complexity_pruning_path(self, X, y, sample_weight=None)\n",
            " |      Compute the pruning path during Minimal Cost-Complexity Pruning.\n",
            " |      \n",
            " |      See :ref:`minimal_cost_complexity_pruning` for details on the pruning\n",
            " |      process.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
            " |          The training input samples. Internally, it will be converted to\n",
            " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
            " |          to a sparse ``csc_matrix``.\n",
            " |      \n",
            " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
            " |          The target values (class labels) as integers or strings.\n",
            " |      \n",
            " |      sample_weight : array-like of shape (n_samples,), default=None\n",
            " |          Sample weights. If None, then samples are equally weighted. Splits\n",
            " |          that would create child nodes with net zero or negative weight are\n",
            " |          ignored while searching for a split in each node. Splits are also\n",
            " |          ignored if they would result in any single class carrying a\n",
            " |          negative weight in either child node.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      ccp_path : :class:`~sklearn.utils.Bunch`\n",
            " |          Dictionary-like object, with the following attributes.\n",
            " |      \n",
            " |          ccp_alphas : ndarray\n",
            " |              Effective alphas of subtree during pruning.\n",
            " |      \n",
            " |          impurities : ndarray\n",
            " |              Sum of the impurities of the subtree leaves for the\n",
            " |              corresponding alpha value in ``ccp_alphas``.\n",
            " |  \n",
            " |  decision_path(self, X, check_input=True)\n",
            " |      Return the decision path in the tree.\n",
            " |      \n",
            " |      .. versionadded:: 0.18\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
            " |          The input samples. Internally, it will be converted to\n",
            " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
            " |          to a sparse ``csr_matrix``.\n",
            " |      \n",
            " |      check_input : bool, default=True\n",
            " |          Allow to bypass several input checking.\n",
            " |          Don't use this parameter unless you know what you're doing.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      indicator : sparse matrix of shape (n_samples, n_nodes)\n",
            " |          Return a node indicator CSR matrix where non zero elements\n",
            " |          indicates that the samples goes through the nodes.\n",
            " |  \n",
            " |  get_depth(self)\n",
            " |      Return the depth of the decision tree.\n",
            " |      \n",
            " |      The depth of a tree is the maximum distance between the root\n",
            " |      and any leaf.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self.tree_.max_depth : int\n",
            " |          The maximum depth of the tree.\n",
            " |  \n",
            " |  get_n_leaves(self)\n",
            " |      Return the number of leaves of the decision tree.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self.tree_.n_leaves : int\n",
            " |          Number of leaves.\n",
            " |  \n",
            " |  predict(self, X, check_input=True)\n",
            " |      Predict class or regression value for X.\n",
            " |      \n",
            " |      For a classification model, the predicted class for each sample in X is\n",
            " |      returned. For a regression model, the predicted value based on X is\n",
            " |      returned.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
            " |          The input samples. Internally, it will be converted to\n",
            " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
            " |          to a sparse ``csr_matrix``.\n",
            " |      \n",
            " |      check_input : bool, default=True\n",
            " |          Allow to bypass several input checking.\n",
            " |          Don't use this parameter unless you know what you're doing.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
            " |          The predicted classes, or the predict values.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Readonly properties inherited from BaseDecisionTree:\n",
            " |  \n",
            " |  feature_importances_\n",
            " |      Return the feature importances.\n",
            " |      \n",
            " |      The importance of a feature is computed as the (normalized) total\n",
            " |      reduction of the criterion brought by that feature.\n",
            " |      It is also known as the Gini importance.\n",
            " |      \n",
            " |      Warning: impurity-based feature importances can be misleading for\n",
            " |      high cardinality features (many unique values). See\n",
            " |      :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      feature_importances_ : ndarray of shape (n_features,)\n",
            " |          Normalized total reduction of criteria by feature\n",
            " |          (Gini importance).\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.base.BaseEstimator:\n",
            " |  \n",
            " |  __getstate__(self)\n",
            " |      Helper for pickle.\n",
            " |  \n",
            " |  __repr__(self, N_CHAR_MAX=700)\n",
            " |      Return repr(self).\n",
            " |  \n",
            " |  __setstate__(self, state)\n",
            " |  \n",
            " |  __sklearn_clone__(self)\n",
            " |  \n",
            " |  get_params(self, deep=True)\n",
            " |      Get parameters for this estimator.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      deep : bool, default=True\n",
            " |          If True, will return the parameters for this estimator and\n",
            " |          contained subobjects that are estimators.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      params : dict\n",
            " |          Parameter names mapped to their values.\n",
            " |  \n",
            " |  set_params(self, **params)\n",
            " |      Set the parameters of this estimator.\n",
            " |      \n",
            " |      The method works on simple estimators as well as on nested objects\n",
            " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
            " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
            " |      possible to update each component of a nested object.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      **params : dict\n",
            " |          Estimator parameters.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : estimator instance\n",
            " |          Estimator instance.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
            " |  \n",
            " |  get_metadata_routing(self)\n",
            " |      Get metadata routing of this object.\n",
            " |      \n",
            " |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
            " |      mechanism works.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      routing : MetadataRequest\n",
            " |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
            " |          routing information.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
            " |  \n",
            " |  __init_subclass__(**kwargs) from abc.ABCMeta\n",
            " |      Set the ``set_{method}_request`` methods.\n",
            " |      \n",
            " |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
            " |      looks for the information available in the set default values which are\n",
            " |      set using ``__metadata_request__*`` class attributes, or inferred\n",
            " |      from method signatures.\n",
            " |      \n",
            " |      The ``__metadata_request__*`` class attributes are used when a method\n",
            " |      does not explicitly accept a metadata through its arguments or if the\n",
            " |      developer would like to specify a request value for those metadata\n",
            " |      which are different from the default ``None``.\n",
            " |      \n",
            " |      References\n",
            " |      ----------\n",
            " |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(DecisionTreeClassifier)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PI1PzVTWROMA"
      },
      "source": [
        "# Hyper Parameter Tuning of DecisionTree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "ubunZ0fARFp0"
      },
      "outputs": [],
      "source": [
        "dt_params = {\n",
        "    'criterion' :['gini','entropy'],\n",
        "    'max_depth' : [3,5,7,10],\n",
        "    'splitter' : ['best','random'],\n",
        "    'min_samples_leaf':[1,2,3,5,7],\n",
        "    'min_samples_split':[1,2,3,5,7],\n",
        "    'max_features' : ['auto','sqrt','log2']\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "id": "SxpUwVU9TDSq",
        "outputId": "b93741a9-2599-4b10-f25b-637fa1f7b43a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 1200 candidates, totalling 6000 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\prave\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
            "2800 fits failed out of a total of 6000.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "1059 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\prave\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"c:\\Users\\prave\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"c:\\Users\\prave\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"c:\\Users\\prave\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of DecisionTreeClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "941 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\prave\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"c:\\Users\\prave\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"c:\\Users\\prave\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"c:\\Users\\prave\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of DecisionTreeClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "800 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\prave\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"c:\\Users\\prave\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"c:\\Users\\prave\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"c:\\Users\\prave\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "c:\\Users\\prave\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan ... 0.925      0.91785714 0.80714286]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(criterion=&#x27;entropy&#x27;),\n",
              "             n_jobs=-1,\n",
              "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
              "                         &#x27;max_depth&#x27;: [3, 5, 7, 10],\n",
              "                         &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
              "                         &#x27;min_samples_leaf&#x27;: [1, 2, 3, 5, 7],\n",
              "                         &#x27;min_samples_split&#x27;: [1, 2, 3, 5, 7],\n",
              "                         &#x27;splitter&#x27;: [&#x27;best&#x27;, &#x27;random&#x27;]},\n",
              "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(criterion=&#x27;entropy&#x27;),\n",
              "             n_jobs=-1,\n",
              "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
              "                         &#x27;max_depth&#x27;: [3, 5, 7, 10],\n",
              "                         &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
              "                         &#x27;min_samples_leaf&#x27;: [1, 2, 3, 5, 7],\n",
              "                         &#x27;min_samples_split&#x27;: [1, 2, 3, 5, 7],\n",
              "                         &#x27;splitter&#x27;: [&#x27;best&#x27;, &#x27;random&#x27;]},\n",
              "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(criterion='entropy'),\n",
              "             n_jobs=-1,\n",
              "             param_grid={'criterion': ['gini', 'entropy'],\n",
              "                         'max_depth': [3, 5, 7, 10],\n",
              "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
              "                         'min_samples_leaf': [1, 2, 3, 5, 7],\n",
              "                         'min_samples_split': [1, 2, 3, 5, 7],\n",
              "                         'splitter': ['best', 'random']},\n",
              "             verbose=1)"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gs_dt = GridSearchCV(\n",
        "    dt,\n",
        "    dt_params,\n",
        "    cv = 5,\n",
        "    n_jobs = -1,\n",
        "    verbose=1\n",
        "\n",
        ")\n",
        "\n",
        "gs_dt.fit(X_train,Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4wKkDhmTx-n",
        "outputId": "0b016fbf-3ad5-4fa5-aef1-b60fd8affc4e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'criterion': 'entropy',\n",
              " 'max_depth': 10,\n",
              " 'max_features': 'log2',\n",
              " 'min_samples_leaf': 1,\n",
              " 'min_samples_split': 7,\n",
              " 'splitter': 'random'}"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gs_dt.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibLNCKm7T7_O",
        "outputId": "79b7341a-d3dd-4197-ac44-c1ea62c5c5c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9857142857142855"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gs_dt.best_score_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "uLYnC1x8UBu_",
        "outputId": "7fba6012-b384-4952-9776-77d166156024"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=10, max_features=&#x27;log2&#x27;,\n",
              "                       min_samples_split=7, splitter=&#x27;random&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=10, max_features=&#x27;log2&#x27;,\n",
              "                       min_samples_split=7, splitter=&#x27;random&#x27;)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "DecisionTreeClassifier(criterion='entropy', max_depth=10, max_features='log2',\n",
              "                       min_samples_split=7, splitter='random')"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gs_dt.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WxCwwHJUf2V",
        "outputId": "5fe500f1-be0a-402b-cc60-6e9c1e4b9812"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracy_score(Y_train,X_train_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGI0dVxMUNN5",
        "outputId": "07d5c713-0660-4cfe-e7ba-5ed1f7388fac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9916666666666667"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracy_score(Y_test,X_test_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGImptRCUmUE",
        "outputId": "8886cf87-881a-442d-cbc6-3518f8936f2b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[69,  1],\n",
              "       [ 0, 50]], dtype=int64)"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "confusion_matrix(Y_test,dt.predict(X_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bVYQh0IU60G",
        "outputId": "63a9a423-10ca-4c47-e1f8-be37d64f655d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[180,   0],\n",
              "       [  0, 100]], dtype=int64)"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "confusion_matrix(Y_train,dt.predict(X_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFi61Y6eVDbX",
        "outputId": "050d65fa-ef58-49f1-adb9-4920c46c6017"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99        70\n",
            "           1       0.98      1.00      0.99        50\n",
            "\n",
            "    accuracy                           0.99       120\n",
            "   macro avg       0.99      0.99      0.99       120\n",
            "weighted avg       0.99      0.99      0.99       120\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(Y_test,dt.predict(X_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5Cm2S1oXnvz"
      },
      "source": [
        "# Bagging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVjCkfrcXqdc"
      },
      "source": [
        "**Random Forest Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "CnyZJUwKXwQN"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "_gAPmby5YRxZ",
        "outputId": "dfb61ab2-d90a-4a7b-8de0-e67fe787b3f6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, n_estimators=50, n_jobs=3,\n",
              "                       oob_score=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, n_estimators=50, n_jobs=3,\n",
              "                       oob_score=True)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "RandomForestClassifier(criterion='entropy', n_estimators=50, n_jobs=3,\n",
              "                       oob_score=True)"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rf = RandomForestClassifier(n_jobs=3,oob_score=True,n_estimators=50,criterion=\"entropy\")\n",
        "rf.fit(X_train,Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2Z3jgltYgfL",
        "outputId": "264969e9-86fd-44c7-8740-13caa205b370"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing Data Accuracy  0.9833333333333333\n"
          ]
        }
      ],
      "source": [
        "print( \"Testing Data Accuracy \" ,accuracy_score(Y_test,rf.predict(X_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXpJLPWiYqYT",
        "outputId": "1632f809-1892-40c4-d59e-120b6c91d087"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Data Accuracy  1.0\n"
          ]
        }
      ],
      "source": [
        "print( \"Training Data Accuracy \" ,accuracy_score(Y_train,rf.predict(X_train)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLe5KRCdZBbq",
        "outputId": "21c05655-88a9-426c-f2a7-9d096f6ff3d0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[69,  1],\n",
              "       [ 1, 49]], dtype=int64)"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "confusion_matrix(Y_test,rf.predict(X_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTqMcMBQZSdX",
        "outputId": "8b36c71e-44a1-4f33-8cc5-244c309684c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99        70\n",
            "           1       0.98      0.98      0.98        50\n",
            "\n",
            "    accuracy                           0.98       120\n",
            "   macro avg       0.98      0.98      0.98       120\n",
            "weighted avg       0.98      0.98      0.98       120\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(Y_test,rf.predict(X_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpSppRGraVqI"
      },
      "source": [
        "# **Ada Boost Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.model_selection import cross_val_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [],
      "source": [
        "clf = AdaBoostClassifier(n_estimators=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostClassifier(n_estimators=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier(n_estimators=100)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "AdaBoostClassifier(n_estimators=100)"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf.fit(X_train,Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1], dtype=int64)"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred = clf.predict(X)\n",
        "pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9833333333333333"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf.score(X_test, Y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWASdxigaZjY"
      },
      "source": [
        "# **Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\prave\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=0)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LogisticRegression(random_state=0)"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier= LogisticRegression(random_state=0)\n",
        "classifier.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Predicting the test set result\n",
        "y_pred= classifier.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.91      0.90        68\n",
            "           1       0.88      0.85      0.86        52\n",
            "\n",
            "    accuracy                           0.88       120\n",
            "   macro avg       0.88      0.88      0.88       120\n",
            "weighted avg       0.88      0.88      0.88       120\n",
            " \n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_pred,Y_test),'\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbZJ4P-Wad1T"
      },
      "source": [
        "# **Naive Bayes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {},
      "outputs": [],
      "source": [
        "imnb = MultinomialNB()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [],
      "source": [
        "pred_mnb = imnb.fit(X_train,Y_train) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
              "       1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
              "       1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "       0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
              "       0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n",
              "       1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1,\n",
              "       0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1,\n",
              "       0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
              "       0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1,\n",
              "       1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0,\n",
              "       0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
              "       1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "       0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0], dtype=int64)"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y_train_pred = pred_mnb.predict(X_train)\n",
        "Y_train_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[139,  41],\n",
              "       [  4,  96]], dtype=int64)"
            ]
          },
          "execution_count": 118,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "confusion_matrix(Y_train,Y_train_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8392857142857143"
            ]
          },
          "execution_count": 119,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracy_score(Y_train,Y_train_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "       1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1,\n",
              "       1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "       0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
              "       1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1,\n",
              "       1, 1, 0, 0, 0, 0, 1, 0, 0, 1], dtype=int64)"
            ]
          },
          "execution_count": 120,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y_pred = pred_mnb.predict(X_test)\n",
        "Y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8583333333333333"
            ]
          },
          "execution_count": 121,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracy_score(Y_test,Y_pred) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qs9av2sfaoCy"
      },
      "source": [
        "# **KNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier as KNC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-8 {color: black;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=3)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "KNeighborsClassifier(n_neighbors=3)"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "neigh = KNC(n_neighbors= 3)\n",
        "neigh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-9 {color: black;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=3)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "KNeighborsClassifier(n_neighbors=3)"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "neigh.fit(X_train,Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0,\n",
              "       0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
              "       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0,\n",
              "       0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n",
              "       1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
              "       0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1,\n",
              "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
              "       1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1,\n",
              "       1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0,\n",
              "       0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1,\n",
              "       1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "       1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0], dtype=int64)"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_pred=neigh.predict(X_train)\n",
        "train_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "90.35714285714286\n"
          ]
        }
      ],
      "source": [
        "train_acc = np.mean(neigh.predict(X_train)==(Y_train))\n",
        "print(train_acc*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "75.83333333333333\n"
          ]
        }
      ],
      "source": [
        "test_acc = np.mean(neigh.predict(X_test)==(Y_test))\n",
        "print(test_acc*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-10 {color: black;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "KNeighborsClassifier()"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# for 5 nearest neighbours\n",
        "neigh = KNC(n_neighbors=5)\n",
        "neigh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-11 {color: black;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "KNeighborsClassifier()"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "neigh.fit(X_train,Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
              "       0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0,\n",
              "       0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
              "       0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0,\n",
              "       0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1,\n",
              "       1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0,\n",
              "       0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1,\n",
              "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
              "       1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1,\n",
              "       1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n",
              "       0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1,\n",
              "       1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "       1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0], dtype=int64)"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_pred=neigh.predict(X_train)\n",
        "train_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "81.07142857142857\n"
          ]
        }
      ],
      "source": [
        "train_acc = np.mean(neigh.predict(X_train)==(Y_train))\n",
        "print(train_acc*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "78.33333333333333\n"
          ]
        }
      ],
      "source": [
        "test_acc = np.mean(neigh.predict(X_test)==(Y_test))\n",
        "print(test_acc*100)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
